2024-10-19 15:41:47,003 INFO: Namespace(concept_cfg='datasets/data_cfgs/MixofShow/multi-concept/object/lora_animal.json', save_path='experiments/gradient_fusion/chilloutmix/lora_animal', suffix='base', pretrained_models='experiments/pretrained_models/chilloutmix', optimize_unet_iters=50, optimize_textenc_iters=500)
2024-10-19 15:41:47,004 INFO: ------Step 1: load stable diffusion checkpoint------
2024-10-19 15:41:53,223 INFO: ------Step 2: load new concepts checkpoints------
2024-10-19 15:41:53,255 INFO: ------Step 3: merge token embedding------
2024-10-19 15:41:53,272 INFO: concept <catA1> is bind with token_id: [49408, 49423]
2024-10-19 15:41:53,277 INFO: concept <catA2> is bind with token_id: [49424, 49439]
2024-10-19 15:41:53,281 INFO: concept <dogA1> is bind with token_id: [49440, 49455]
2024-10-19 15:41:53,285 INFO: concept <dogA2> is bind with token_id: [49456, 49471]
2024-10-19 15:41:53,289 INFO: concept <dogB1> is bind with token_id: [49472, 49487]
2024-10-19 15:41:53,293 INFO: concept <dogB2> is bind with token_id: [49488, 49503]
2024-10-19 15:41:53,293 INFO: ------Step 4: merge text encoder------
2024-10-19 15:41:53,293 INFO: text_encoder have 48 linear layer need to optimize
2024-10-19 15:41:53,293 INFO: add 48 hooker to text_encoder
2024-10-19 15:41:53,359 INFO: load 48 LoRAs of text_encoder
2024-10-19 15:41:54,706 INFO: load 48 LoRAs of text_encoder
2024-10-19 15:41:55,788 INFO: load 48 LoRAs of text_encoder
2024-10-19 15:41:56,840 INFO: [1/48] optimizing text_model.encoder.layers.3.self_attn.q_proj.weight
2024-10-19 15:42:08,486 INFO: new_concept loss: 6.604351e-03
2024-10-19 15:42:08,486 INFO: [2/48] optimizing text_model.encoder.layers.2.self_attn.q_proj.weight
2024-10-19 15:42:19,895 INFO: new_concept loss: 9.972667e-03
2024-10-19 15:42:19,895 INFO: [3/48] optimizing text_model.encoder.layers.8.self_attn.out_proj.weight
2024-10-19 15:42:30,149 INFO: new_concept loss: 2.323154e-03
2024-10-19 15:42:30,149 INFO: [4/48] optimizing text_model.encoder.layers.1.self_attn.k_proj.weight
2024-10-19 15:42:41,332 INFO: new_concept loss: 1.782519e-02
2024-10-19 15:42:41,332 INFO: [5/48] optimizing text_model.encoder.layers.5.self_attn.q_proj.weight
2024-10-19 15:42:52,494 INFO: new_concept loss: 8.335448e-03
2024-10-19 15:42:52,495 INFO: [6/48] optimizing text_model.encoder.layers.7.self_attn.v_proj.weight
2024-10-19 15:43:03,831 INFO: new_concept loss: 8.474433e-03
2024-10-19 15:43:03,831 INFO: [7/48] optimizing text_model.encoder.layers.2.self_attn.v_proj.weight
2024-10-19 15:43:14,998 INFO: new_concept loss: 1.136410e-02
2024-10-19 15:43:14,998 INFO: [8/48] optimizing text_model.encoder.layers.3.self_attn.k_proj.weight
2024-10-19 15:43:26,071 INFO: new_concept loss: 7.456056e-03
2024-10-19 15:43:26,071 INFO: [9/48] optimizing text_model.encoder.layers.4.self_attn.k_proj.weight
2024-10-19 15:43:37,370 INFO: new_concept loss: 8.308942e-03
2024-10-19 15:43:37,371 INFO: [10/48] optimizing text_model.encoder.layers.5.self_attn.v_proj.weight
2024-10-19 15:43:48,486 INFO: new_concept loss: 1.093397e-02
2024-10-19 15:43:48,486 INFO: [11/48] optimizing text_model.encoder.layers.4.self_attn.v_proj.weight
2024-10-19 15:43:59,587 INFO: new_concept loss: 8.472933e-03
2024-10-19 15:43:59,587 INFO: [12/48] optimizing text_model.encoder.layers.5.self_attn.out_proj.weight
2024-10-19 15:44:06,143 INFO: new_concept loss: 2.358417e-03
2024-10-19 15:44:06,144 INFO: [13/48] optimizing text_model.encoder.layers.7.self_attn.k_proj.weight
2024-10-19 15:44:17,790 INFO: new_concept loss: 6.180059e-03
2024-10-19 15:44:17,790 INFO: [14/48] optimizing text_model.encoder.layers.2.self_attn.k_proj.weight
2024-10-19 15:44:28,923 INFO: new_concept loss: 1.321810e-02
2024-10-19 15:44:28,923 INFO: [15/48] optimizing text_model.encoder.layers.0.self_attn.q_proj.weight
2024-10-19 15:44:33,801 INFO: new_concept loss: 1.255639e-02
2024-10-19 15:44:33,802 INFO: [16/48] optimizing text_model.encoder.layers.9.self_attn.k_proj.weight
2024-10-19 15:44:44,589 INFO: new_concept loss: 7.334766e-03
2024-10-19 15:44:44,589 INFO: [17/48] optimizing text_model.encoder.layers.6.self_attn.k_proj.weight
2024-10-19 15:44:55,719 INFO: new_concept loss: 5.934052e-03
2024-10-19 15:44:55,720 INFO: [18/48] optimizing text_model.encoder.layers.11.self_attn.out_proj.weight
2024-10-19 15:45:05,778 INFO: new_concept loss: 2.997527e-03
2024-10-19 15:45:05,779 INFO: [19/48] optimizing text_model.encoder.layers.10.self_attn.q_proj.weight
2024-10-19 15:45:17,152 INFO: new_concept loss: 6.333991e-03
2024-10-19 15:45:17,153 INFO: [20/48] optimizing text_model.encoder.layers.11.self_attn.q_proj.weight
2024-10-19 15:45:28,128 INFO: new_concept loss: 9.996628e-03
2024-10-19 15:45:28,128 INFO: [21/48] optimizing text_model.encoder.layers.6.self_attn.q_proj.weight
2024-10-19 15:45:39,190 INFO: new_concept loss: 6.432576e-03
2024-10-19 15:45:39,190 INFO: [22/48] optimizing text_model.encoder.layers.1.self_attn.v_proj.weight
2024-10-19 15:45:49,126 INFO: new_concept loss: 1.018198e-02
2024-10-19 15:45:49,126 INFO: [23/48] optimizing text_model.encoder.layers.5.self_attn.k_proj.weight
2024-10-19 15:46:00,404 INFO: new_concept loss: 6.861418e-03
2024-10-19 15:46:00,405 INFO: [24/48] optimizing text_model.encoder.layers.4.self_attn.q_proj.weight
2024-10-19 15:46:11,716 INFO: new_concept loss: 6.859601e-03
2024-10-19 15:46:11,716 INFO: [25/48] optimizing text_model.encoder.layers.2.self_attn.out_proj.weight
2024-10-19 15:46:18,184 INFO: new_concept loss: 1.202346e-03
2024-10-19 15:46:18,184 INFO: [26/48] optimizing text_model.encoder.layers.3.self_attn.out_proj.weight
2024-10-19 15:46:25,622 INFO: new_concept loss: 1.463127e-03
2024-10-19 15:46:25,622 INFO: [27/48] optimizing text_model.encoder.layers.1.self_attn.out_proj.weight
2024-10-19 15:46:30,698 INFO: new_concept loss: 1.018509e-03
2024-10-19 15:46:30,698 INFO: [28/48] optimizing text_model.encoder.layers.9.self_attn.q_proj.weight
2024-10-19 15:46:41,345 INFO: new_concept loss: 4.576176e-03
2024-10-19 15:46:41,346 INFO: [29/48] optimizing text_model.encoder.layers.10.self_attn.v_proj.weight
2024-10-19 15:46:52,349 INFO: new_concept loss: 9.166405e-03
2024-10-19 15:46:52,349 INFO: [30/48] optimizing text_model.encoder.layers.7.self_attn.q_proj.weight
2024-10-19 15:47:03,383 INFO: new_concept loss: 7.048638e-03
2024-10-19 15:47:03,383 INFO: [31/48] optimizing text_model.encoder.layers.8.self_attn.v_proj.weight
2024-10-19 15:47:14,213 INFO: new_concept loss: 8.221463e-03
2024-10-19 15:47:14,214 INFO: [32/48] optimizing text_model.encoder.layers.9.self_attn.v_proj.weight
2024-10-19 15:47:25,596 INFO: new_concept loss: 6.130678e-03
2024-10-19 15:47:25,597 INFO: [33/48] optimizing text_model.encoder.layers.4.self_attn.out_proj.weight
2024-10-19 15:47:30,616 INFO: new_concept loss: 1.923344e-03
2024-10-19 15:47:30,616 INFO: [34/48] optimizing text_model.encoder.layers.0.self_attn.out_proj.weight
2024-10-19 15:47:39,066 INFO: new_concept loss: 2.513129e-03
2024-10-19 15:47:39,067 INFO: [35/48] optimizing text_model.encoder.layers.11.self_attn.v_proj.weight
2024-10-19 15:47:50,557 INFO: new_concept loss: 7.403893e-03
2024-10-19 15:47:50,557 INFO: [36/48] optimizing text_model.encoder.layers.0.self_attn.k_proj.weight
2024-10-19 15:47:54,228 INFO: new_concept loss: 1.592752e-02
2024-10-19 15:47:54,229 INFO: [37/48] optimizing text_model.encoder.layers.8.self_attn.k_proj.weight
2024-10-19 15:48:05,236 INFO: new_concept loss: 7.094467e-03
2024-10-19 15:48:05,236 INFO: [38/48] optimizing text_model.encoder.layers.1.self_attn.q_proj.weight
2024-10-19 15:48:13,894 INFO: new_concept loss: 9.841358e-03
2024-10-19 15:48:13,895 INFO: [39/48] optimizing text_model.encoder.layers.3.self_attn.v_proj.weight
2024-10-19 15:48:25,025 INFO: new_concept loss: 1.071411e-02
2024-10-19 15:48:25,026 INFO: [40/48] optimizing text_model.encoder.layers.6.self_attn.out_proj.weight
2024-10-19 15:48:33,408 INFO: new_concept loss: 1.361502e-03
2024-10-19 15:48:33,408 INFO: [41/48] optimizing text_model.encoder.layers.7.self_attn.out_proj.weight
2024-10-19 15:48:41,959 INFO: new_concept loss: 1.482993e-03
2024-10-19 15:48:41,959 INFO: [42/48] optimizing text_model.encoder.layers.8.self_attn.q_proj.weight
2024-10-19 15:48:52,907 INFO: new_concept loss: 6.145868e-03
2024-10-19 15:48:52,908 INFO: [43/48] optimizing text_model.encoder.layers.6.self_attn.v_proj.weight
2024-10-19 15:49:03,613 INFO: new_concept loss: 7.659940e-03
2024-10-19 15:49:03,613 INFO: [44/48] optimizing text_model.encoder.layers.9.self_attn.out_proj.weight
2024-10-19 15:49:11,865 INFO: new_concept loss: 2.095399e-03
2024-10-19 15:49:11,865 INFO: [45/48] optimizing text_model.encoder.layers.0.self_attn.v_proj.weight
2024-10-19 15:49:16,032 INFO: new_concept loss: 1.293626e-02
2024-10-19 15:49:16,033 INFO: [46/48] optimizing text_model.encoder.layers.10.self_attn.k_proj.weight
2024-10-19 15:49:27,457 INFO: new_concept loss: 6.567514e-03
2024-10-19 15:49:27,458 INFO: [47/48] optimizing text_model.encoder.layers.11.self_attn.k_proj.weight
2024-10-19 15:49:38,313 INFO: new_concept loss: 5.184928e-03
2024-10-19 15:49:38,313 INFO: [48/48] optimizing text_model.encoder.layers.10.self_attn.out_proj.weight
2024-10-19 15:49:48,397 INFO: new_concept loss: 2.216462e-03
2024-10-19 15:49:48,398 INFO: remove 48 hooker from text_encoder
2024-10-19 15:49:48,440 INFO: ------Step 5: merge kv of cross-attention in unet------
2024-10-19 15:49:48,443 INFO: Unet have 32 linear layer (related to text feature) need to optimize
2024-10-19 15:49:50,424 INFO: [1/32] optimizing down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:49:57,890 INFO: new_concept loss: 1.729976e-05
2024-10-19 15:49:57,890 INFO: [2/32] optimizing down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:50:04,539 INFO: new_concept loss: 7.555553e-06
2024-10-19 15:50:04,540 INFO: [3/32] optimizing down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:50:13,035 INFO: new_concept loss: 1.712819e-05
2024-10-19 15:50:13,036 INFO: [4/32] optimizing down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:50:22,382 INFO: new_concept loss: 5.469719e-06
2024-10-19 15:50:22,383 INFO: [5/32] optimizing down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:50:32,384 INFO: new_concept loss: 2.001408e-05
2024-10-19 15:50:32,384 INFO: [6/32] optimizing down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:50:38,141 INFO: new_concept loss: 8.224459e-06
2024-10-19 15:50:38,142 INFO: [7/32] optimizing down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:50:44,851 INFO: new_concept loss: 1.429727e-05
2024-10-19 15:50:44,851 INFO: [8/32] optimizing down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:50:47,080 INFO: new_concept loss: 4.500642e-06
2024-10-19 15:50:47,081 INFO: [9/32] optimizing down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:50:57,352 INFO: new_concept loss: 2.927452e-05
2024-10-19 15:50:57,353 INFO: [10/32] optimizing down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:51:09,024 INFO: new_concept loss: 2.225201e-05
2024-10-19 15:51:09,025 INFO: [11/32] optimizing down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:51:18,181 INFO: new_concept loss: 3.165741e-05
2024-10-19 15:51:18,181 INFO: [12/32] optimizing down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:51:30,592 INFO: new_concept loss: 1.801877e-05
2024-10-19 15:51:30,593 INFO: [13/32] optimizing mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:51:42,342 INFO: new_concept loss: 4.081870e-05
2024-10-19 15:51:42,343 INFO: [14/32] optimizing mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:51:54,110 INFO: new_concept loss: 4.971052e-05
2024-10-19 15:51:54,111 INFO: [15/32] optimizing up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:52:05,964 INFO: new_concept loss: 3.934941e-05
2024-10-19 15:52:05,964 INFO: [16/32] optimizing up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:52:17,379 INFO: new_concept loss: 5.561671e-05
2024-10-19 15:52:17,380 INFO: [17/32] optimizing up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:52:23,349 INFO: new_concept loss: 1.887070e-05
2024-10-19 15:52:23,349 INFO: [18/32] optimizing up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:52:29,346 INFO: new_concept loss: 1.852345e-05
2024-10-19 15:52:29,346 INFO: [19/32] optimizing up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:52:37,774 INFO: new_concept loss: 2.606495e-05
2024-10-19 15:52:37,774 INFO: [20/32] optimizing up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:52:48,503 INFO: new_concept loss: 9.882858e-05
2024-10-19 15:52:48,504 INFO: [21/32] optimizing up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:52:54,985 INFO: new_concept loss: 1.730775e-05
2024-10-19 15:52:54,986 INFO: [22/32] optimizing up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:52:59,881 INFO: new_concept loss: 1.315908e-05
2024-10-19 15:52:59,882 INFO: [23/32] optimizing up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:53:08,816 INFO: new_concept loss: 4.556201e-05
2024-10-19 15:53:08,816 INFO: [24/32] optimizing up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:53:17,362 INFO: new_concept loss: 3.049346e-05
2024-10-19 15:53:17,362 INFO: [25/32] optimizing up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:53:26,078 INFO: new_concept loss: 4.420370e-05
2024-10-19 15:53:26,079 INFO: [26/32] optimizing up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:53:34,185 INFO: new_concept loss: 4.008178e-05
2024-10-19 15:53:34,186 INFO: [27/32] optimizing up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:53:40,731 INFO: new_concept loss: 1.931631e-05
2024-10-19 15:53:40,732 INFO: [28/32] optimizing up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:53:47,469 INFO: new_concept loss: 9.031572e-06
2024-10-19 15:53:47,469 INFO: [29/32] optimizing up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:53:49,525 INFO: new_concept loss: 1.268976e-05
2024-10-19 15:53:49,526 INFO: [30/32] optimizing up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:53:51,420 INFO: new_concept loss: 3.221067e-06
2024-10-19 15:53:51,421 INFO: [31/32] optimizing up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_k.weight
2024-10-19 15:53:57,542 INFO: new_concept loss: 4.569993e-05
2024-10-19 15:53:57,543 INFO: [32/32] optimizing up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_v.weight
2024-10-19 15:54:01,385 INFO: new_concept loss: 1.156185e-05
2024-10-19 15:54:01,431 INFO: ------Step 6: merge spatial attention (q in cross-attention, qkv in self-attention) in unet------
2024-10-19 15:54:01,431 INFO: unet have 96 linear layer need to optimize
2024-10-19 15:54:01,434 INFO: add 96 hooker to unet
2024-10-19 15:54:01,605 INFO: load 96 LoRAs of unet
2024-10-19 15:54:08,826 INFO: load 96 LoRAs of unet
2024-10-19 15:54:13,048 INFO: load 96 LoRAs of unet
2024-10-19 15:54:18,311 INFO: [1/96] optimizing up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight
2024-10-19 15:54:20,597 INFO: new_concept loss: 2.218517e-01
2024-10-19 15:54:20,609 INFO: [2/96] optimizing down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:54:24,011 INFO: new_concept loss: 8.458850e-02
2024-10-19 15:54:24,035 INFO: [3/96] optimizing down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 15:54:30,416 INFO: new_concept loss: 4.647261e-02
2024-10-19 15:54:30,460 INFO: [4/96] optimizing down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight
2024-10-19 15:54:38,284 INFO: new_concept loss: 8.260240e-02
2024-10-19 15:54:38,329 INFO: [5/96] optimizing mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight
2024-10-19 15:54:39,514 INFO: new_concept loss: 6.255153e-02
2024-10-19 15:54:39,514 INFO: [6/96] optimizing down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight
2024-10-19 15:54:41,791 INFO: new_concept loss: 8.653525e-02
2024-10-19 15:54:41,806 INFO: [7/96] optimizing down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 15:54:44,113 INFO: new_concept loss: 5.067011e-02
2024-10-19 15:54:44,127 INFO: [8/96] optimizing down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight
2024-10-19 15:54:51,591 INFO: new_concept loss: 9.328020e-02
2024-10-19 15:54:51,642 INFO: [9/96] optimizing up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight
2024-10-19 15:54:53,968 INFO: new_concept loss: 1.076295e-01
2024-10-19 15:54:53,983 INFO: [10/96] optimizing up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight
2024-10-19 15:54:56,405 INFO: new_concept loss: 9.539279e-02
2024-10-19 15:54:56,420 INFO: [11/96] optimizing mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:54:57,550 INFO: new_concept loss: 5.329218e-02
2024-10-19 15:54:57,551 INFO: [12/96] optimizing down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 15:54:59,877 INFO: new_concept loss: 5.357505e-02
2024-10-19 15:54:59,891 INFO: [13/96] optimizing down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight
2024-10-19 15:55:06,727 INFO: new_concept loss: 8.531880e-02
2024-10-19 15:55:06,782 INFO: [14/96] optimizing down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight
2024-10-19 15:55:13,637 INFO: new_concept loss: 2.444074e-02
2024-10-19 15:55:13,693 INFO: [15/96] optimizing up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_v.weight
2024-10-19 15:55:20,581 INFO: new_concept loss: 1.016373e-01
2024-10-19 15:55:20,631 INFO: [16/96] optimizing down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 15:55:23,977 INFO: new_concept loss: 7.073222e-02
2024-10-19 15:55:24,007 INFO: [17/96] optimizing down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 15:55:26,625 INFO: new_concept loss: 4.093941e-02
2024-10-19 15:55:26,639 INFO: [18/96] optimizing up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_v.weight
2024-10-19 15:55:33,926 INFO: new_concept loss: 6.628616e-02
2024-10-19 15:55:33,987 INFO: [19/96] optimizing down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight
2024-10-19 15:55:36,625 INFO: new_concept loss: 3.588672e-02
2024-10-19 15:55:36,643 INFO: [20/96] optimizing down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:55:40,464 INFO: new_concept loss: 8.867491e-02
2024-10-19 15:55:40,495 INFO: [21/96] optimizing down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight
2024-10-19 15:55:42,903 INFO: new_concept loss: 9.007822e-02
2024-10-19 15:55:42,919 INFO: [22/96] optimizing down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 15:55:49,881 INFO: new_concept loss: 3.156204e-02
2024-10-19 15:55:49,935 INFO: [23/96] optimizing up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_v.weight
2024-10-19 15:55:53,996 INFO: new_concept loss: 1.204924e-01
2024-10-19 15:55:54,029 INFO: [24/96] optimizing up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight
2024-10-19 15:55:57,722 INFO: new_concept loss: 2.417661e-01
2024-10-19 15:55:57,773 INFO: [25/96] optimizing up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 15:56:01,617 INFO: new_concept loss: 3.085116e-01
2024-10-19 15:56:01,648 INFO: [26/96] optimizing down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 15:56:04,062 INFO: new_concept loss: 1.164506e-01
2024-10-19 15:56:04,081 INFO: [27/96] optimizing up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight
2024-10-19 15:56:06,601 INFO: new_concept loss: 8.227203e-02
2024-10-19 15:56:06,618 INFO: [28/96] optimizing up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_q.weight
2024-10-19 15:56:13,494 INFO: new_concept loss: 5.072618e-02
2024-10-19 15:56:13,559 INFO: [29/96] optimizing down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 15:56:17,204 INFO: new_concept loss: 7.328819e-02
2024-10-19 15:56:17,237 INFO: [30/96] optimizing up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_q.weight
2024-10-19 15:56:21,226 INFO: new_concept loss: 1.837020e-01
2024-10-19 15:56:21,262 INFO: [31/96] optimizing up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:56:24,792 INFO: new_concept loss: 1.923469e-01
2024-10-19 15:56:24,828 INFO: [32/96] optimizing up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 15:56:28,528 INFO: new_concept loss: 1.442111e-01
2024-10-19 15:56:28,564 INFO: [33/96] optimizing up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_k.weight
2024-10-19 15:56:36,394 INFO: new_concept loss: 1.726037e-01
2024-10-19 15:56:36,458 INFO: [34/96] optimizing mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 15:56:37,735 INFO: new_concept loss: 1.863802e-01
2024-10-19 15:56:37,736 INFO: [35/96] optimizing up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 15:56:40,196 INFO: new_concept loss: 1.257832e-01
2024-10-19 15:56:40,209 INFO: [36/96] optimizing up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_k.weight
2024-10-19 15:56:43,814 INFO: new_concept loss: 2.802275e-01
2024-10-19 15:56:43,855 INFO: [37/96] optimizing down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight
2024-10-19 15:56:48,159 INFO: new_concept loss: 1.123190e-01
2024-10-19 15:56:48,196 INFO: [38/96] optimizing up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight
2024-10-19 15:56:50,382 INFO: new_concept loss: 8.031400e-02
2024-10-19 15:56:50,400 INFO: [39/96] optimizing up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:56:57,733 INFO: new_concept loss: 8.226355e-02
2024-10-19 15:56:57,786 INFO: [40/96] optimizing down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight
2024-10-19 15:57:01,419 INFO: new_concept loss: 4.375305e-02
2024-10-19 15:57:01,457 INFO: [41/96] optimizing up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight
2024-10-19 15:57:03,868 INFO: new_concept loss: 2.877655e-01
2024-10-19 15:57:03,887 INFO: [42/96] optimizing up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight
2024-10-19 15:57:07,501 INFO: new_concept loss: 1.557659e-01
2024-10-19 15:57:07,535 INFO: [43/96] optimizing down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 15:57:11,440 INFO: new_concept loss: 5.463506e-02
2024-10-19 15:57:11,473 INFO: [44/96] optimizing up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:57:13,975 INFO: new_concept loss: 1.527175e-01
2024-10-19 15:57:13,994 INFO: [45/96] optimizing up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 15:57:21,128 INFO: new_concept loss: 1.635363e-02
2024-10-19 15:57:21,181 INFO: [46/96] optimizing up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight
2024-10-19 15:57:25,220 INFO: new_concept loss: 2.344552e-01
2024-10-19 15:57:25,266 INFO: [47/96] optimizing up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight
2024-10-19 15:57:28,789 INFO: new_concept loss: 1.700206e-01
2024-10-19 15:57:28,823 INFO: [48/96] optimizing up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_q.weight
2024-10-19 15:57:36,004 INFO: new_concept loss: 6.323157e-02
2024-10-19 15:57:36,065 INFO: [49/96] optimizing down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight
2024-10-19 15:57:43,028 INFO: new_concept loss: 7.688062e-02
2024-10-19 15:57:43,092 INFO: [50/96] optimizing down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight
2024-10-19 15:57:45,584 INFO: new_concept loss: 3.691376e-02
2024-10-19 15:57:45,603 INFO: [51/96] optimizing up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:57:53,244 INFO: new_concept loss: 2.669282e-01
2024-10-19 15:57:53,314 INFO: [52/96] optimizing mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight
2024-10-19 15:57:54,354 INFO: new_concept loss: 7.204406e-02
2024-10-19 15:57:54,355 INFO: [53/96] optimizing mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 15:57:55,542 INFO: new_concept loss: 5.778772e-02
2024-10-19 15:57:55,543 INFO: [54/96] optimizing down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:57:57,761 INFO: new_concept loss: 8.816196e-02
2024-10-19 15:57:57,778 INFO: [55/96] optimizing down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:58:05,385 INFO: new_concept loss: 8.116973e-02
2024-10-19 15:58:05,440 INFO: [56/96] optimizing down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight
2024-10-19 15:58:07,797 INFO: new_concept loss: 1.144806e-01
2024-10-19 15:58:07,812 INFO: [57/96] optimizing mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight
2024-10-19 15:58:08,934 INFO: new_concept loss: 3.090339e-02
2024-10-19 15:58:08,935 INFO: [58/96] optimizing up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:58:16,096 INFO: new_concept loss: 1.423462e-01
2024-10-19 15:58:16,143 INFO: [59/96] optimizing down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:58:22,653 INFO: new_concept loss: 8.949266e-02
2024-10-19 15:58:22,698 INFO: [60/96] optimizing up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:58:26,459 INFO: new_concept loss: 3.051011e-01
2024-10-19 15:58:26,487 INFO: [61/96] optimizing up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 15:58:30,668 INFO: new_concept loss: 5.906311e-01
2024-10-19 15:58:30,696 INFO: [62/96] optimizing up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight
2024-10-19 15:58:34,858 INFO: new_concept loss: 3.290272e-01
2024-10-19 15:58:34,884 INFO: [63/96] optimizing up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:58:37,313 INFO: new_concept loss: 1.897583e-01
2024-10-19 15:58:37,330 INFO: [64/96] optimizing down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight
2024-10-19 15:58:40,863 INFO: new_concept loss: 1.396796e-01
2024-10-19 15:58:40,892 INFO: [65/96] optimizing up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 15:58:48,141 INFO: new_concept loss: 9.776226e-02
2024-10-19 15:58:48,202 INFO: [66/96] optimizing down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 15:58:55,442 INFO: new_concept loss: 3.353363e-02
2024-10-19 15:58:55,498 INFO: [67/96] optimizing up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 15:58:58,835 INFO: new_concept loss: 1.668680e-01
2024-10-19 15:58:58,870 INFO: [68/96] optimizing up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 15:59:05,920 INFO: new_concept loss: 6.375949e-02
2024-10-19 15:59:05,980 INFO: [69/96] optimizing down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 15:59:09,260 INFO: new_concept loss: 6.493136e-02
2024-10-19 15:59:09,295 INFO: [70/96] optimizing up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:59:11,679 INFO: new_concept loss: 1.352446e-01
2024-10-19 15:59:11,699 INFO: [71/96] optimizing up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 15:59:18,962 INFO: new_concept loss: 1.432182e-02
2024-10-19 15:59:19,016 INFO: [72/96] optimizing up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_v.weight
2024-10-19 15:59:26,069 INFO: new_concept loss: 2.073233e-01
2024-10-19 15:59:26,123 INFO: [73/96] optimizing up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:59:29,666 INFO: new_concept loss: 2.277764e-01
2024-10-19 15:59:29,701 INFO: [74/96] optimizing up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_k.weight
2024-10-19 15:59:35,635 INFO: new_concept loss: 1.164763e-01
2024-10-19 15:59:35,690 INFO: [75/96] optimizing up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_q.weight
2024-10-19 15:59:41,222 INFO: new_concept loss: 3.366762e-02
2024-10-19 15:59:41,281 INFO: [76/96] optimizing up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 15:59:42,952 INFO: new_concept loss: 2.159403e-01
2024-10-19 15:59:42,974 INFO: [77/96] optimizing down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight
2024-10-19 15:59:44,728 INFO: new_concept loss: 6.051483e-02
2024-10-19 15:59:44,748 INFO: [78/96] optimizing up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 15:59:47,566 INFO: new_concept loss: 7.175060e-02
2024-10-19 15:59:47,596 INFO: [79/96] optimizing up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight
2024-10-19 15:59:49,301 INFO: new_concept loss: 2.156788e-01
2024-10-19 15:59:49,319 INFO: [80/96] optimizing up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight
2024-10-19 15:59:51,036 INFO: new_concept loss: 2.410045e-01
2024-10-19 15:59:51,054 INFO: [81/96] optimizing up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 15:59:52,863 INFO: new_concept loss: 8.388825e-02
2024-10-19 15:59:52,882 INFO: [82/96] optimizing down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight
2024-10-19 15:59:54,683 INFO: new_concept loss: 4.999616e-02
2024-10-19 15:59:54,704 INFO: [83/96] optimizing up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 16:00:00,786 INFO: new_concept loss: 9.443206e-03
2024-10-19 16:00:00,839 INFO: [84/96] optimizing down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight
2024-10-19 16:00:06,248 INFO: new_concept loss: 3.725808e-02
2024-10-19 16:00:06,302 INFO: [85/96] optimizing down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight
2024-10-19 16:00:09,031 INFO: new_concept loss: 8.438408e-02
2024-10-19 16:00:09,064 INFO: [86/96] optimizing up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight
2024-10-19 16:00:10,746 INFO: new_concept loss: 1.190070e-01
2024-10-19 16:00:10,765 INFO: [87/96] optimizing up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 16:00:16,049 INFO: new_concept loss: 3.031930e-02
2024-10-19 16:00:16,103 INFO: [88/96] optimizing up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_k.weight
2024-10-19 16:00:21,459 INFO: new_concept loss: 7.883980e-02
2024-10-19 16:00:21,516 INFO: [89/96] optimizing up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 16:00:24,223 INFO: new_concept loss: 9.063593e-02
2024-10-19 16:00:24,261 INFO: [90/96] optimizing down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 16:00:29,202 INFO: new_concept loss: 2.541163e-02
2024-10-19 16:00:29,271 INFO: [91/96] optimizing up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight
2024-10-19 16:00:31,487 INFO: new_concept loss: 2.382142e-01
2024-10-19 16:00:31,523 INFO: [92/96] optimizing up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight
2024-10-19 16:00:33,031 INFO: new_concept loss: 1.661689e-01
2024-10-19 16:00:33,051 INFO: [93/96] optimizing down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight
2024-10-19 16:00:35,313 INFO: new_concept loss: 1.190516e-01
2024-10-19 16:00:35,358 INFO: [94/96] optimizing up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 16:00:36,874 INFO: new_concept loss: 1.945607e-01
2024-10-19 16:00:36,894 INFO: [95/96] optimizing up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight
2024-10-19 16:00:38,346 INFO: new_concept loss: 1.642452e-01
2024-10-19 16:00:38,366 INFO: [96/96] optimizing down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight
2024-10-19 16:00:40,541 INFO: new_concept loss: 4.413706e-02
2024-10-19 16:00:40,579 INFO: remove 96 hooker from unet
