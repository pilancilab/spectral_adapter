2024-10-19 16:02:59,104 INFO: Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: fp16

2024-10-19 16:02:59,104 INFO: 
  name: catA_spectral(idx=2)
  manual_seed: 0
  spectral_idx: 2
  mixed_precision: fp16
  gradient_accumulation_steps: 1
  datasets:[
    train:[
      name: LoraDataset
      concept_list: datasets/data_cfgs/MixofShow/single-concept/objects/real/catA.json
      use_caption: True
      instance_transform: [{'type': 'Resize', 'size': 512}, {'type': 'RandomCrop', 'size': 512}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': [0.5], 'std': [0.5]}, {'type': 'ShuffleCaption', 'keep_token_num': 1}, {'type': 'EnhanceText', 'enhance_type': 'object'}]
      replace_mapping:[
        <TOK>: <catA1> <catA2>
      ]
      batch_size_per_gpu: 2
      dataset_enlarge_ratio: 500
    ]
    val_vis:[
      name: PromptDataset
      prompts: datasets/validation_prompts/single-concept/objects/test_cat.txt
      num_samples_per_prompt: 8
      latent_size: [4, 64, 64]
      replace_mapping:[
        <TOK>: <catA1> <catA2>
      ]
      batch_size_per_gpu: 4
    ]
  ]
  models:[
    pretrained_path: experiments/pretrained_models/chilloutmix
    enable_edlora: True
    finetune_cfg:[
      text_embedding:[
        enable_tuning: True
        lr: 0.001
      ]
      text_encoder:[
        enable_tuning: True
        lora_cfg:[
          rank: 8
          alpha: 1.0
          where: CLIPAttention
        ]
        lr: 1e-05
      ]
      unet:[
        enable_tuning: True
        lora_cfg:[
          rank: 8
          alpha: 1.0
          where: Attention
        ]
        lr: 0.0001
      ]
    ]
    new_concept_token: <catA1>+<catA2>
    initializer_token: <rand-0.013>+cat
    noise_offset: 0.01
    attn_reg_weight: 0.01
    reg_full_identity: False
    use_mask_loss: True
    gradient_checkpoint: False
    enable_xformers: True
  ]
  path:[
    pretrain_network: None
    experiments_root: /media/hdd2/zfzhao/fusion_reprod1/mix_spectral/experiments/catA_spectral(idx=2)
    models: /media/hdd2/zfzhao/fusion_reprod1/mix_spectral/experiments/catA_spectral(idx=2)/models
    log: /media/hdd2/zfzhao/fusion_reprod1/mix_spectral/experiments/catA_spectral(idx=2)
    visualization: /media/hdd2/zfzhao/fusion_reprod1/mix_spectral/experiments/catA_spectral(idx=2)/visualization
  ]
  train:[
    optim_g:[
      type: AdamW
      lr: 0.0
      weight_decay: 0.01
      betas: [0.9, 0.999]
    ]
    unet_kv_drop_rate: 0
    scheduler: linear
    emb_norm_threshold: 0.55
  ]
  val:[
    val_during_save: True
    compose_visualize: True
    alpha_list: [0, 0.7, 1.0]
    sample:[
      num_inference_steps: 50
      guidance_scale: 7.5
    ]
  ]
  logger:[
    print_freq: 10
    save_checkpoint_freq: 10000.0
  ]
  is_train: True

2024-10-19 16:03:02,062 INFO: <catA1> (49408-49423) is random initialized by: <rand-0.013>
2024-10-19 16:03:02,283 INFO: <catA2> (49424-49439) is random initialized by existing token (cat): 2368
2024-10-19 16:03:02,287 INFO: optimizing embedding using lr: 0.001
2024-10-19 16:03:07,852 INFO: optimizing text_encoder (48 LoRAs), using lr: 1e-05
2024-10-19 16:03:29,916 INFO: optimizing unet (128 LoRAs), using lr: 0.0001
2024-10-19 16:03:32,691 INFO: ***** Running training *****
2024-10-19 16:03:32,692 INFO:   Num examples = 2500
2024-10-19 16:03:32,692 INFO:   Instantaneous batch size per device = 2
2024-10-19 16:03:32,692 INFO:   Total train batch size (w. parallel, distributed & accumulation) = 2
2024-10-19 16:03:32,692 INFO:   Total optimization steps = 1250.0
2024-10-19 16:03:42,661 INFO: [catA_..][Iter:      10, lr:(9.920e-04,9.920e-06,9.920e-05,)] [eta: 0:18:42] loss: 3.7073e-02 Norm_mean: 3.8376e-01 
2024-10-19 16:03:50,883 INFO: [catA_..][Iter:      20, lr:(9.840e-04,9.840e-06,9.840e-05,)] [eta: 0:17:44] loss: 1.9953e-01 Norm_mean: 3.9764e-01 
2024-10-19 16:03:59,181 INFO: [catA_..][Iter:      30, lr:(9.760e-04,9.760e-06,9.760e-05,)] [eta: 0:17:21] loss: 2.6905e-01 Norm_mean: 4.0883e-01 
2024-10-19 16:04:07,640 INFO: [catA_..][Iter:      40, lr:(9.680e-04,9.680e-06,9.680e-05,)] [eta: 0:17:10] loss: 6.9161e-01 Norm_mean: 4.1835e-01 
2024-10-19 16:04:15,684 INFO: [catA_..][Iter:      50, lr:(9.600e-04,9.600e-06,9.600e-05,)] [eta: 0:16:50] loss: 6.1744e-02 Norm_mean: 4.2720e-01 
2024-10-19 16:04:23,723 INFO: [catA_..][Iter:      60, lr:(9.520e-04,9.520e-06,9.520e-05,)] [eta: 0:16:34] loss: 6.3467e-01 Norm_mean: 4.3463e-01 
2024-10-19 16:04:32,137 INFO: [catA_..][Iter:      70, lr:(9.440e-04,9.440e-06,9.440e-05,)] [eta: 0:16:27] loss: 6.4546e-01 Norm_mean: 4.4108e-01 
2024-10-19 16:04:39,607 INFO: [catA_..][Iter:      80, lr:(9.360e-04,9.360e-06,9.360e-05,)] [eta: 0:16:05] loss: 1.6409e-01 Norm_mean: 4.4720e-01 
2024-10-19 16:04:47,530 INFO: [catA_..][Iter:      90, lr:(9.280e-04,9.280e-06,9.280e-05,)] [eta: 0:15:53] loss: 1.7370e-02 Norm_mean: 4.5305e-01 
2024-10-19 16:04:55,609 INFO: [catA_..][Iter:     100, lr:(9.200e-04,9.200e-06,9.200e-05,)] [eta: 0:15:43] loss: 2.4867e-01 Norm_mean: 4.5881e-01 
2024-10-19 16:05:03,732 INFO: [catA_..][Iter:     110, lr:(9.120e-04,9.120e-06,9.120e-05,)] [eta: 0:15:34] loss: 3.9440e-01 Norm_mean: 4.6425e-01 
2024-10-19 16:05:11,441 INFO: [catA_..][Iter:     120, lr:(9.040e-04,9.040e-06,9.040e-05,)] [eta: 0:15:21] loss: 6.8415e-01 Norm_mean: 4.6890e-01 
2024-10-19 16:05:19,974 INFO: [catA_..][Iter:     130, lr:(8.960e-04,8.960e-06,8.960e-05,)] [eta: 0:15:16] loss: 3.3109e-01 Norm_mean: 4.7319e-01 
2024-10-19 16:05:28,619 INFO: [catA_..][Iter:     140, lr:(8.880e-04,8.880e-06,8.880e-05,)] [eta: 0:15:11] loss: 1.4558e+00 Norm_mean: 4.7826e-01 
2024-10-19 16:05:36,918 INFO: [catA_..][Iter:     150, lr:(8.800e-04,8.800e-06,8.800e-05,)] [eta: 0:15:04] loss: 1.0862e-01 Norm_mean: 4.8340e-01 
2024-10-19 16:05:44,976 INFO: [catA_..][Iter:     160, lr:(8.720e-04,8.720e-06,8.720e-05,)] [eta: 0:14:54] loss: 8.5831e-01 Norm_mean: 4.8808e-01 
2024-10-19 16:05:53,541 INFO: [catA_..][Iter:     170, lr:(8.640e-04,8.640e-06,8.640e-05,)] [eta: 0:14:48] loss: 6.8381e-02 Norm_mean: 4.9220e-01 
2024-10-19 16:06:02,048 INFO: [catA_..][Iter:     180, lr:(8.560e-04,8.560e-06,8.560e-05,)] [eta: 0:14:42] loss: 4.1884e-02 Norm_mean: 4.9783e-01 
2024-10-19 16:06:10,400 INFO: [catA_..][Iter:     190, lr:(8.480e-04,8.480e-06,8.480e-05,)] [eta: 0:14:34] loss: 1.0166e-01 Norm_mean: 5.0391e-01 
2024-10-19 16:06:18,511 INFO: [catA_..][Iter:     200, lr:(8.400e-04,8.400e-06,8.400e-05,)] [eta: 0:14:25] loss: 5.9555e-01 Norm_mean: 5.0901e-01 
2024-10-19 16:06:26,935 INFO: [catA_..][Iter:     210, lr:(8.320e-04,8.320e-06,8.320e-05,)] [eta: 0:14:18] loss: 5.7234e-01 Norm_mean: 5.1377e-01 
2024-10-19 16:06:35,391 INFO: [catA_..][Iter:     220, lr:(8.240e-04,8.240e-06,8.240e-05,)] [eta: 0:14:10] loss: 1.0278e+00 Norm_mean: 5.1854e-01 
2024-10-19 16:06:43,424 INFO: [catA_..][Iter:     230, lr:(8.160e-04,8.160e-06,8.160e-05,)] [eta: 0:14:01] loss: 2.2456e-01 Norm_mean: 5.2334e-01 
2024-10-19 16:06:51,544 INFO: [catA_..][Iter:     240, lr:(8.080e-04,8.080e-06,8.080e-05,)] [eta: 0:13:52] loss: 9.4718e-01 Norm_mean: 5.2747e-01 
2024-10-19 16:06:59,812 INFO: [catA_..][Iter:     250, lr:(8.000e-04,8.000e-06,8.000e-05,)] [eta: 0:13:44] loss: 9.5733e-01 Norm_mean: 5.3131e-01 
2024-10-19 16:07:08,067 INFO: [catA_..][Iter:     260, lr:(7.920e-04,7.920e-06,7.920e-05,)] [eta: 0:13:36] loss: 2.9190e-01 Norm_mean: 5.3472e-01 
2024-10-19 16:07:16,290 INFO: [catA_..][Iter:     270, lr:(7.840e-04,7.840e-06,7.840e-05,)] [eta: 0:13:27] loss: 5.7574e-01 Norm_mean: 5.3791e-01 
2024-10-19 16:07:24,290 INFO: [catA_..][Iter:     280, lr:(7.760e-04,7.760e-06,7.760e-05,)] [eta: 0:13:18] loss: 4.0303e-01 Norm_mean: 5.4142e-01 
2024-10-19 16:07:32,258 INFO: [catA_..][Iter:     290, lr:(7.680e-04,7.680e-06,7.680e-05,)] [eta: 0:13:09] loss: 4.4018e-01 Norm_mean: 5.4462e-01 
2024-10-19 16:07:40,458 INFO: [catA_..][Iter:     300, lr:(7.600e-04,7.600e-06,7.600e-05,)] [eta: 0:13:01] loss: 2.9651e-01 Norm_mean: 5.4782e-01 
2024-10-19 16:07:48,683 INFO: [catA_..][Iter:     310, lr:(7.520e-04,7.520e-06,7.520e-05,)] [eta: 0:12:52] loss: 7.2903e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:07:56,322 INFO: [catA_..][Iter:     320, lr:(7.440e-04,7.440e-06,7.440e-05,)] [eta: 0:12:42] loss: 3.7654e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:08:03,857 INFO: [catA_..][Iter:     330, lr:(7.360e-04,7.360e-06,7.360e-05,)] [eta: 0:12:32] loss: 1.5284e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:08:12,491 INFO: [catA_..][Iter:     340, lr:(7.280e-04,7.280e-06,7.280e-05,)] [eta: 0:12:25] loss: 7.8980e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:08:21,103 INFO: [catA_..][Iter:     350, lr:(7.200e-04,7.200e-06,7.200e-05,)] [eta: 0:12:18] loss: 4.0370e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:08:29,446 INFO: [catA_..][Iter:     360, lr:(7.120e-04,7.120e-06,7.120e-05,)] [eta: 0:12:10] loss: 4.9500e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:08:37,863 INFO: [catA_..][Iter:     370, lr:(7.040e-04,7.040e-06,7.040e-05,)] [eta: 0:12:03] loss: 4.5810e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:08:46,861 INFO: [catA_..][Iter:     380, lr:(6.960e-04,6.960e-06,6.960e-05,)] [eta: 0:11:56] loss: 2.2102e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:08:54,988 INFO: [catA_..][Iter:     390, lr:(6.880e-04,6.880e-06,6.880e-05,)] [eta: 0:11:48] loss: 8.1532e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:09:03,609 INFO: [catA_..][Iter:     400, lr:(6.800e-04,6.800e-06,6.800e-05,)] [eta: 0:11:40] loss: 1.1644e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:09:12,184 INFO: [catA_..][Iter:     410, lr:(6.720e-04,6.720e-06,6.720e-05,)] [eta: 0:11:33] loss: 5.6216e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:09:20,884 INFO: [catA_..][Iter:     420, lr:(6.640e-04,6.640e-06,6.640e-05,)] [eta: 0:11:25] loss: 3.6108e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:09:28,772 INFO: [catA_..][Iter:     430, lr:(6.560e-04,6.560e-06,6.560e-05,)] [eta: 0:11:16] loss: 3.4252e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:09:37,068 INFO: [catA_..][Iter:     440, lr:(6.480e-04,6.480e-06,6.480e-05,)] [eta: 0:11:08] loss: 1.3424e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:09:45,217 INFO: [catA_..][Iter:     450, lr:(6.400e-04,6.400e-06,6.400e-05,)] [eta: 0:10:59] loss: 2.4922e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:09:52,937 INFO: [catA_..][Iter:     460, lr:(6.320e-04,6.320e-06,6.320e-05,)] [eta: 0:10:50] loss: 1.6577e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:10:00,988 INFO: [catA_..][Iter:     470, lr:(6.240e-04,6.240e-06,6.240e-05,)] [eta: 0:10:42] loss: 2.3951e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:10:09,818 INFO: [catA_..][Iter:     480, lr:(6.160e-04,6.160e-06,6.160e-05,)] [eta: 0:10:34] loss: 3.6725e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:10:17,945 INFO: [catA_..][Iter:     490, lr:(6.080e-04,6.080e-06,6.080e-05,)] [eta: 0:10:26] loss: 2.9977e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:10:25,877 INFO: [catA_..][Iter:     500, lr:(6.000e-04,6.000e-06,6.000e-05,)] [eta: 0:10:17] loss: 6.1792e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:10:34,197 INFO: [catA_..][Iter:     510, lr:(5.920e-04,5.920e-06,5.920e-05,)] [eta: 0:10:09] loss: 6.6253e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:10:42,244 INFO: [catA_..][Iter:     520, lr:(5.840e-04,5.840e-06,5.840e-05,)] [eta: 0:10:01] loss: 1.3946e+00 Norm_mean: 5.5013e-01 
2024-10-19 16:10:50,841 INFO: [catA_..][Iter:     530, lr:(5.760e-04,5.760e-06,5.760e-05,)] [eta: 0:09:53] loss: 2.4534e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:10:58,931 INFO: [catA_..][Iter:     540, lr:(5.680e-04,5.680e-06,5.680e-05,)] [eta: 0:09:44] loss: 6.4133e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:11:07,171 INFO: [catA_..][Iter:     550, lr:(5.600e-04,5.600e-06,5.600e-05,)] [eta: 0:09:36] loss: 6.7239e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:11:14,856 INFO: [catA_..][Iter:     560, lr:(5.520e-04,5.520e-06,5.520e-05,)] [eta: 0:09:27] loss: 5.0920e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:11:23,065 INFO: [catA_..][Iter:     570, lr:(5.440e-04,5.440e-06,5.440e-05,)] [eta: 0:09:19] loss: 1.4173e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:11:31,259 INFO: [catA_..][Iter:     580, lr:(5.360e-04,5.360e-06,5.360e-05,)] [eta: 0:09:11] loss: 2.7119e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:11:39,231 INFO: [catA_..][Iter:     590, lr:(5.280e-04,5.280e-06,5.280e-05,)] [eta: 0:09:02] loss: 3.8417e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:11:47,313 INFO: [catA_..][Iter:     600, lr:(5.200e-04,5.200e-06,5.200e-05,)] [eta: 0:08:54] loss: 5.9760e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:11:55,626 INFO: [catA_..][Iter:     610, lr:(5.120e-04,5.120e-06,5.120e-05,)] [eta: 0:08:45] loss: 1.9664e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:12:03,781 INFO: [catA_..][Iter:     620, lr:(5.040e-04,5.040e-06,5.040e-05,)] [eta: 0:08:37] loss: 5.1676e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:12:11,575 INFO: [catA_..][Iter:     630, lr:(4.960e-04,4.960e-06,4.960e-05,)] [eta: 0:08:29] loss: 5.6236e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:12:19,372 INFO: [catA_..][Iter:     640, lr:(4.880e-04,4.880e-06,4.880e-05,)] [eta: 0:08:20] loss: 3.3874e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:12:27,800 INFO: [catA_..][Iter:     650, lr:(4.800e-04,4.800e-06,4.800e-05,)] [eta: 0:08:12] loss: 1.0280e+00 Norm_mean: 5.5013e-01 
2024-10-19 16:12:36,119 INFO: [catA_..][Iter:     660, lr:(4.720e-04,4.720e-06,4.720e-05,)] [eta: 0:08:04] loss: 2.0650e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:12:44,557 INFO: [catA_..][Iter:     670, lr:(4.640e-04,4.640e-06,4.640e-05,)] [eta: 0:07:56] loss: 3.9391e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:12:52,523 INFO: [catA_..][Iter:     680, lr:(4.560e-04,4.560e-06,4.560e-05,)] [eta: 0:07:47] loss: 8.4474e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:13:00,755 INFO: [catA_..][Iter:     690, lr:(4.480e-04,4.480e-06,4.480e-05,)] [eta: 0:07:39] loss: 2.4261e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:13:08,543 INFO: [catA_..][Iter:     700, lr:(4.400e-04,4.400e-06,4.400e-05,)] [eta: 0:07:30] loss: 1.3066e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:13:16,762 INFO: [catA_..][Iter:     710, lr:(4.320e-04,4.320e-06,4.320e-05,)] [eta: 0:07:22] loss: 7.6008e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:13:24,723 INFO: [catA_..][Iter:     720, lr:(4.240e-04,4.240e-06,4.240e-05,)] [eta: 0:07:14] loss: 3.0030e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:13:32,586 INFO: [catA_..][Iter:     730, lr:(4.160e-04,4.160e-06,4.160e-05,)] [eta: 0:07:05] loss: 3.1205e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:13:40,781 INFO: [catA_..][Iter:     740, lr:(4.080e-04,4.080e-06,4.080e-05,)] [eta: 0:06:57] loss: 1.7555e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:13:48,982 INFO: [catA_..][Iter:     750, lr:(4.000e-04,4.000e-06,4.000e-05,)] [eta: 0:06:49] loss: 7.3304e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:13:57,167 INFO: [catA_..][Iter:     760, lr:(3.920e-04,3.920e-06,3.920e-05,)] [eta: 0:06:41] loss: 9.7743e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:14:05,360 INFO: [catA_..][Iter:     770, lr:(3.840e-04,3.840e-06,3.840e-05,)] [eta: 0:06:33] loss: 5.5313e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:14:13,401 INFO: [catA_..][Iter:     780, lr:(3.760e-04,3.760e-06,3.760e-05,)] [eta: 0:06:24] loss: 5.4203e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:14:21,714 INFO: [catA_..][Iter:     790, lr:(3.680e-04,3.680e-06,3.680e-05,)] [eta: 0:06:16] loss: 7.1724e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:14:30,242 INFO: [catA_..][Iter:     800, lr:(3.600e-04,3.600e-06,3.600e-05,)] [eta: 0:06:08] loss: 1.8461e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:14:38,624 INFO: [catA_..][Iter:     810, lr:(3.520e-04,3.520e-06,3.520e-05,)] [eta: 0:06:00] loss: 4.4658e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:14:47,197 INFO: [catA_..][Iter:     820, lr:(3.440e-04,3.440e-06,3.440e-05,)] [eta: 0:05:52] loss: 7.7322e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:14:54,523 INFO: [catA_..][Iter:     830, lr:(3.360e-04,3.360e-06,3.360e-05,)] [eta: 0:05:43] loss: 1.0112e+00 Norm_mean: 5.5013e-01 
2024-10-19 16:15:02,738 INFO: [catA_..][Iter:     840, lr:(3.280e-04,3.280e-06,3.280e-05,)] [eta: 0:05:35] loss: 8.1737e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:15:11,112 INFO: [catA_..][Iter:     850, lr:(3.200e-04,3.200e-06,3.200e-05,)] [eta: 0:05:27] loss: 1.3148e+00 Norm_mean: 5.5013e-01 
2024-10-19 16:15:19,185 INFO: [catA_..][Iter:     860, lr:(3.120e-04,3.120e-06,3.120e-05,)] [eta: 0:05:19] loss: 1.0226e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:15:27,346 INFO: [catA_..][Iter:     870, lr:(3.040e-04,3.040e-06,3.040e-05,)] [eta: 0:05:10] loss: 7.5795e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:15:35,101 INFO: [catA_..][Iter:     880, lr:(2.960e-04,2.960e-06,2.960e-05,)] [eta: 0:05:02] loss: 2.0030e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:15:43,609 INFO: [catA_..][Iter:     890, lr:(2.880e-04,2.880e-06,2.880e-05,)] [eta: 0:04:54] loss: 8.9693e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:15:51,354 INFO: [catA_..][Iter:     900, lr:(2.800e-04,2.800e-06,2.800e-05,)] [eta: 0:04:46] loss: 1.1949e+00 Norm_mean: 5.5013e-01 
2024-10-19 16:15:59,281 INFO: [catA_..][Iter:     910, lr:(2.720e-04,2.720e-06,2.720e-05,)] [eta: 0:04:37] loss: 5.6838e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:16:07,056 INFO: [catA_..][Iter:     920, lr:(2.640e-04,2.640e-06,2.640e-05,)] [eta: 0:04:29] loss: 1.3554e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:16:14,971 INFO: [catA_..][Iter:     930, lr:(2.560e-04,2.560e-06,2.560e-05,)] [eta: 0:04:21] loss: 5.9533e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:16:22,946 INFO: [catA_..][Iter:     940, lr:(2.480e-04,2.480e-06,2.480e-05,)] [eta: 0:04:12] loss: 1.2021e+00 Norm_mean: 5.5013e-01 
2024-10-19 16:16:31,340 INFO: [catA_..][Iter:     950, lr:(2.400e-04,2.400e-06,2.400e-05,)] [eta: 0:04:04] loss: 3.4527e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:16:39,380 INFO: [catA_..][Iter:     960, lr:(2.320e-04,2.320e-06,2.320e-05,)] [eta: 0:03:56] loss: 2.2824e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:16:47,362 INFO: [catA_..][Iter:     970, lr:(2.240e-04,2.240e-06,2.240e-05,)] [eta: 0:03:48] loss: 5.5835e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:16:55,286 INFO: [catA_..][Iter:     980, lr:(2.160e-04,2.160e-06,2.160e-05,)] [eta: 0:03:40] loss: 1.2352e+00 Norm_mean: 5.5013e-01 
2024-10-19 16:17:03,250 INFO: [catA_..][Iter:     990, lr:(2.080e-04,2.080e-06,2.080e-05,)] [eta: 0:03:31] loss: 1.2597e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:17:11,611 INFO: [catA_..][Iter:   1,000, lr:(2.000e-04,2.000e-06,2.000e-05,)] [eta: 0:03:23] loss: 2.2736e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:17:19,799 INFO: [catA_..][Iter:   1,010, lr:(1.920e-04,1.920e-06,1.920e-05,)] [eta: 0:03:15] loss: 5.2161e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:17:27,851 INFO: [catA_..][Iter:   1,020, lr:(1.840e-04,1.840e-06,1.840e-05,)] [eta: 0:03:07] loss: 1.0243e+00 Norm_mean: 5.5013e-01 
2024-10-19 16:17:36,346 INFO: [catA_..][Iter:   1,030, lr:(1.760e-04,1.760e-06,1.760e-05,)] [eta: 0:02:59] loss: 4.4362e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:17:44,444 INFO: [catA_..][Iter:   1,040, lr:(1.680e-04,1.680e-06,1.680e-05,)] [eta: 0:02:51] loss: 1.2186e+00 Norm_mean: 5.5013e-01 
2024-10-19 16:17:52,630 INFO: [catA_..][Iter:   1,050, lr:(1.600e-04,1.600e-06,1.600e-05,)] [eta: 0:02:42] loss: 2.1102e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:18:00,861 INFO: [catA_..][Iter:   1,060, lr:(1.520e-04,1.520e-06,1.520e-05,)] [eta: 0:02:34] loss: 5.8577e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:18:08,673 INFO: [catA_..][Iter:   1,070, lr:(1.440e-04,1.440e-06,1.440e-05,)] [eta: 0:02:26] loss: 6.5333e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:18:17,170 INFO: [catA_..][Iter:   1,080, lr:(1.360e-04,1.360e-06,1.360e-05,)] [eta: 0:02:18] loss: 2.0598e+00 Norm_mean: 5.5013e-01 
2024-10-19 16:18:25,254 INFO: [catA_..][Iter:   1,090, lr:(1.280e-04,1.280e-06,1.280e-05,)] [eta: 0:02:10] loss: 2.0846e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:18:33,646 INFO: [catA_..][Iter:   1,100, lr:(1.200e-04,1.200e-06,1.200e-05,)] [eta: 0:02:01] loss: 6.3206e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:18:41,608 INFO: [catA_..][Iter:   1,110, lr:(1.120e-04,1.120e-06,1.120e-05,)] [eta: 0:01:53] loss: 1.0015e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:18:49,475 INFO: [catA_..][Iter:   1,120, lr:(1.040e-04,1.040e-06,1.040e-05,)] [eta: 0:01:45] loss: 4.0616e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:18:57,801 INFO: [catA_..][Iter:   1,130, lr:(9.600e-05,9.600e-07,9.600e-06,)] [eta: 0:01:37] loss: 3.7725e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:19:05,757 INFO: [catA_..][Iter:   1,140, lr:(8.800e-05,8.800e-07,8.800e-06,)] [eta: 0:01:29] loss: 7.5200e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:19:13,664 INFO: [catA_..][Iter:   1,150, lr:(8.000e-05,8.000e-07,8.000e-06,)] [eta: 0:01:20] loss: 6.4565e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:19:21,742 INFO: [catA_..][Iter:   1,160, lr:(7.200e-05,7.200e-07,7.200e-06,)] [eta: 0:01:12] loss: 1.7231e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:19:30,115 INFO: [catA_..][Iter:   1,170, lr:(6.400e-05,6.400e-07,6.400e-06,)] [eta: 0:01:04] loss: 1.8235e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:19:38,546 INFO: [catA_..][Iter:   1,180, lr:(5.600e-05,5.600e-07,5.600e-06,)] [eta: 0:00:56] loss: 3.5910e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:19:46,619 INFO: [catA_..][Iter:   1,190, lr:(4.800e-05,4.800e-07,4.800e-06,)] [eta: 0:00:48] loss: 5.5637e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:19:54,973 INFO: [catA_..][Iter:   1,200, lr:(4.000e-05,4.000e-07,4.000e-06,)] [eta: 0:00:40] loss: 2.4526e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:20:02,532 INFO: [catA_..][Iter:   1,210, lr:(3.200e-05,3.200e-07,3.200e-06,)] [eta: 0:00:31] loss: 1.1852e+00 Norm_mean: 5.5013e-01 
2024-10-19 16:20:10,887 INFO: [catA_..][Iter:   1,220, lr:(2.400e-05,2.400e-07,2.400e-06,)] [eta: 0:00:23] loss: 2.1548e-01 Norm_mean: 5.5013e-01 
2024-10-19 16:20:18,772 INFO: [catA_..][Iter:   1,230, lr:(1.600e-05,1.600e-07,1.600e-06,)] [eta: 0:00:15] loss: 2.5329e+00 Norm_mean: 5.5013e-01 
2024-10-19 16:20:27,074 INFO: [catA_..][Iter:   1,240, lr:(8.000e-06,8.000e-08,8.000e-07,)] [eta: 0:00:07] loss: 6.2936e-02 Norm_mean: 5.5013e-01 
2024-10-19 16:20:34,811 INFO: [catA_..][Iter:   1,250, lr:(0.000e+00,0.000e+00,0.000e+00,)] [eta: 0:00:00] loss: 1.4506e+00 Norm_mean: 5.5013e-01 
2024-10-19 16:20:37,365 INFO: Save state to /media/hdd2/zfzhao/fusion_reprod1/mix_spectral/experiments/catA_spectral(idx=2)/models/edlora_model-latest.pth
2024-10-19 16:20:37,365 INFO: Start validation /media/hdd2/zfzhao/fusion_reprod1/mix_spectral/experiments/catA_spectral(idx=2)/models/edlora_model-latest.pth:
