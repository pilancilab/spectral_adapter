2024-10-21 22:02:41,605 INFO: Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: fp16

2024-10-21 22:02:41,606 INFO: 
  name: vase_r3
  manual_seed: 0
  mixed_precision: fp16
  gradient_accumulation_steps: 1
  datasets:[
    train:[
      name: LoraDataset
      concept_list: datasets/data_cfgs/MixofShow/single-concept/objects/real/vase.json
      use_caption: True
      instance_transform: [{'type': 'Resize', 'size': 512}, {'type': 'RandomCrop', 'size': 512}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': [0.5], 'std': [0.5]}, {'type': 'ShuffleCaption', 'keep_token_num': 1}, {'type': 'EnhanceText', 'enhance_type': 'object'}]
      replace_mapping:[
        <TOK>: <vase1> <vase2>
      ]
      batch_size_per_gpu: 2
      dataset_enlarge_ratio: 500
    ]
    val_vis:[
      name: PromptDataset
      prompts: datasets/validation_prompts/single-concept/objects/test_vase.txt
      num_samples_per_prompt: 8
      latent_size: [4, 64, 64]
      replace_mapping:[
        <TOK>: <vase1> <vase2>
      ]
      batch_size_per_gpu: 4
    ]
  ]
  models:[
    pretrained_path: experiments/pretrained_models/chilloutmix
    enable_edlora: True
    finetune_cfg:[
      text_embedding:[
        enable_tuning: False
        lr: 0.001
      ]
      text_encoder:[
        enable_tuning: True
        lora_cfg:[
          rank: 3
          alpha: 1.0
          where: CLIPAttention
        ]
        lr: 1e-05
      ]
      unet:[
        enable_tuning: True
        lora_cfg:[
          rank: 3
          alpha: 1.0
          where: Attention
        ]
        lr: 0.0001
      ]
    ]
    new_concept_token: <vase1>+<vase2>
    initializer_token: <rand-0.013>+vase
    noise_offset: 0.01
    attn_reg_weight: 0.01
    reg_full_identity: False
    use_mask_loss: True
    gradient_checkpoint: False
    enable_xformers: True
  ]
  path:[
    pretrain_network: None
    experiments_root: /media/hdd2/zfzhao/mix_cleanup2/mix_lora/Mix-of-Show/experiments/vase_r3
    models: /media/hdd2/zfzhao/mix_cleanup2/mix_lora/Mix-of-Show/experiments/vase_r3/models
    log: /media/hdd2/zfzhao/mix_cleanup2/mix_lora/Mix-of-Show/experiments/vase_r3
    visualization: /media/hdd2/zfzhao/mix_cleanup2/mix_lora/Mix-of-Show/experiments/vase_r3/visualization
  ]
  train:[
    optim_g:[
      type: AdamW
      lr: 0.0
      weight_decay: 0.01
      betas: [0.9, 0.999]
    ]
    unet_kv_drop_rate: 0
    scheduler: linear
    emb_norm_threshold: 0.55
  ]
  val:[
    val_during_save: True
    compose_visualize: True
    alpha_list: [0, 0.7, 1.0]
    sample:[
      num_inference_steps: 50
      guidance_scale: 7.5
    ]
  ]
  logger:[
    print_freq: 10
    save_checkpoint_freq: 10000.0
  ]
  is_train: True

2024-10-21 22:02:44,327 INFO: <vase1> (49408-49423) is random initialized by: <rand-0.013>
2024-10-21 22:02:44,582 INFO: <vase2> (49424-49439) is random initialized by existing token (vase): 20431
2024-10-21 22:02:44,597 INFO: optimizing text_encoder (48 LoRAs), using lr: 1e-05
2024-10-21 22:02:44,623 INFO: optimizing unet (128 LoRAs), using lr: 0.0001
2024-10-21 22:02:45,440 INFO: ***** Running training *****
2024-10-21 22:02:45,441 INFO:   Num examples = 3000
2024-10-21 22:02:45,441 INFO:   Instantaneous batch size per device = 2
2024-10-21 22:02:45,441 INFO:   Total train batch size (w. parallel, distributed & accumulation) = 2
2024-10-21 22:02:45,441 INFO:   Total optimization steps = 1500.0
2024-10-21 22:02:49,762 INFO: [vase_..][Iter:      10, lr:(9.933e-06,9.933e-05,)] [eta: 0:09:44] loss: 3.1133e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:02:53,520 INFO: [vase_..][Iter:      20, lr:(9.867e-06,9.867e-05,)] [eta: 0:09:29] loss: 7.3640e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:02:57,095 INFO: [vase_..][Iter:      30, lr:(9.800e-06,9.800e-05,)] [eta: 0:09:12] loss: 1.4427e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:03:00,651 INFO: [vase_..][Iter:      40, lr:(9.733e-06,9.733e-05,)] [eta: 0:09:01] loss: 5.5277e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:03:04,201 INFO: [vase_..][Iter:      50, lr:(9.667e-06,9.667e-05,)] [eta: 0:08:53] loss: 2.4003e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:03:07,766 INFO: [vase_..][Iter:      60, lr:(9.600e-06,9.600e-05,)] [eta: 0:08:46] loss: 5.0924e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:03:11,326 INFO: [vase_..][Iter:      70, lr:(9.533e-06,9.533e-05,)] [eta: 0:08:40] loss: 5.2902e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:03:14,881 INFO: [vase_..][Iter:      80, lr:(9.467e-06,9.467e-05,)] [eta: 0:08:35] loss: 1.4992e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:03:18,459 INFO: [vase_..][Iter:      90, lr:(9.400e-06,9.400e-05,)] [eta: 0:08:31] loss: 1.0455e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:03:21,990 INFO: [vase_..][Iter:     100, lr:(9.333e-06,9.333e-05,)] [eta: 0:08:26] loss: 1.1516e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:03:25,545 INFO: [vase_..][Iter:     110, lr:(9.267e-06,9.267e-05,)] [eta: 0:08:21] loss: 2.2380e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:03:29,114 INFO: [vase_..][Iter:     120, lr:(9.200e-06,9.200e-05,)] [eta: 0:08:17] loss: 5.5930e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:03:32,647 INFO: [vase_..][Iter:     130, lr:(9.133e-06,9.133e-05,)] [eta: 0:08:13] loss: 1.4251e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:03:36,226 INFO: [vase_..][Iter:     140, lr:(9.067e-06,9.067e-05,)] [eta: 0:08:09] loss: 1.2685e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:03:39,787 INFO: [vase_..][Iter:     150, lr:(9.000e-06,9.000e-05,)] [eta: 0:08:05] loss: 4.5461e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:03:43,346 INFO: [vase_..][Iter:     160, lr:(8.933e-06,8.933e-05,)] [eta: 0:08:01] loss: 4.9989e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:03:46,903 INFO: [vase_..][Iter:     170, lr:(8.867e-06,8.867e-05,)] [eta: 0:07:57] loss: 5.3539e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:03:50,472 INFO: [vase_..][Iter:     180, lr:(8.800e-06,8.800e-05,)] [eta: 0:07:53] loss: 2.2176e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:03:54,033 INFO: [vase_..][Iter:     190, lr:(8.733e-06,8.733e-05,)] [eta: 0:07:50] loss: 8.6734e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:03:57,588 INFO: [vase_..][Iter:     200, lr:(8.667e-06,8.667e-05,)] [eta: 0:07:46] loss: 2.9937e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:04:01,163 INFO: [vase_..][Iter:     210, lr:(8.600e-06,8.600e-05,)] [eta: 0:07:42] loss: 4.8502e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:04:04,720 INFO: [vase_..][Iter:     220, lr:(8.533e-06,8.533e-05,)] [eta: 0:07:38] loss: 6.0438e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:04:08,279 INFO: [vase_..][Iter:     230, lr:(8.467e-06,8.467e-05,)] [eta: 0:07:35] loss: 1.1657e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:04:11,826 INFO: [vase_..][Iter:     240, lr:(8.400e-06,8.400e-05,)] [eta: 0:07:31] loss: 6.7296e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:04:15,378 INFO: [vase_..][Iter:     250, lr:(8.333e-06,8.333e-05,)] [eta: 0:07:27] loss: 8.1097e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:04:18,940 INFO: [vase_..][Iter:     260, lr:(8.267e-06,8.267e-05,)] [eta: 0:07:23] loss: 2.4786e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:04:22,501 INFO: [vase_..][Iter:     270, lr:(8.200e-06,8.200e-05,)] [eta: 0:07:20] loss: 4.8545e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:04:26,056 INFO: [vase_..][Iter:     280, lr:(8.133e-06,8.133e-05,)] [eta: 0:07:16] loss: 3.1691e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:04:29,622 INFO: [vase_..][Iter:     290, lr:(8.067e-06,8.067e-05,)] [eta: 0:07:12] loss: 2.9007e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:04:33,184 INFO: [vase_..][Iter:     300, lr:(8.000e-06,8.000e-05,)] [eta: 0:07:09] loss: 2.5141e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:04:36,737 INFO: [vase_..][Iter:     310, lr:(7.933e-06,7.933e-05,)] [eta: 0:07:05] loss: 4.5583e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:04:40,306 INFO: [vase_..][Iter:     320, lr:(7.867e-06,7.867e-05,)] [eta: 0:07:01] loss: 2.2779e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:04:43,883 INFO: [vase_..][Iter:     330, lr:(7.800e-06,7.800e-05,)] [eta: 0:06:58] loss: 6.6272e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:04:47,439 INFO: [vase_..][Iter:     340, lr:(7.733e-06,7.733e-05,)] [eta: 0:06:54] loss: 4.7087e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:04:51,009 INFO: [vase_..][Iter:     350, lr:(7.667e-06,7.667e-05,)] [eta: 0:06:51] loss: 2.9853e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:04:54,564 INFO: [vase_..][Iter:     360, lr:(7.600e-06,7.600e-05,)] [eta: 0:06:47] loss: 2.6308e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:04:58,125 INFO: [vase_..][Iter:     370, lr:(7.533e-06,7.533e-05,)] [eta: 0:06:43] loss: 3.6525e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:05:01,690 INFO: [vase_..][Iter:     380, lr:(7.467e-06,7.467e-05,)] [eta: 0:06:40] loss: 1.9034e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:05:05,255 INFO: [vase_..][Iter:     390, lr:(7.400e-06,7.400e-05,)] [eta: 0:06:36] loss: 4.9979e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:05:08,819 INFO: [vase_..][Iter:     400, lr:(7.333e-06,7.333e-05,)] [eta: 0:06:32] loss: 8.5891e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:05:12,364 INFO: [vase_..][Iter:     410, lr:(7.267e-06,7.267e-05,)] [eta: 0:06:29] loss: 4.8356e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:05:15,917 INFO: [vase_..][Iter:     420, lr:(7.200e-06,7.200e-05,)] [eta: 0:06:25] loss: 1.7961e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:05:19,496 INFO: [vase_..][Iter:     430, lr:(7.133e-06,7.133e-05,)] [eta: 0:06:22] loss: 1.7327e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:05:23,062 INFO: [vase_..][Iter:     440, lr:(7.067e-06,7.067e-05,)] [eta: 0:06:18] loss: 1.0373e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:05:26,630 INFO: [vase_..][Iter:     450, lr:(7.000e-06,7.000e-05,)] [eta: 0:06:14] loss: 2.1309e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:05:30,193 INFO: [vase_..][Iter:     460, lr:(6.933e-06,6.933e-05,)] [eta: 0:06:11] loss: 9.4581e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:05:33,760 INFO: [vase_..][Iter:     470, lr:(6.867e-06,6.867e-05,)] [eta: 0:06:07] loss: 1.4323e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:05:37,313 INFO: [vase_..][Iter:     480, lr:(6.800e-06,6.800e-05,)] [eta: 0:06:04] loss: 2.5484e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:05:40,871 INFO: [vase_..][Iter:     490, lr:(6.733e-06,6.733e-05,)] [eta: 0:06:00] loss: 2.2768e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:05:44,437 INFO: [vase_..][Iter:     500, lr:(6.667e-06,6.667e-05,)] [eta: 0:05:56] loss: 3.3417e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:05:48,017 INFO: [vase_..][Iter:     510, lr:(6.600e-06,6.600e-05,)] [eta: 0:05:53] loss: 5.5936e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:05:51,576 INFO: [vase_..][Iter:     520, lr:(6.533e-06,6.533e-05,)] [eta: 0:05:49] loss: 9.4193e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:05:55,136 INFO: [vase_..][Iter:     530, lr:(6.467e-06,6.467e-05,)] [eta: 0:05:46] loss: 2.0743e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:05:58,659 INFO: [vase_..][Iter:     540, lr:(6.400e-06,6.400e-05,)] [eta: 0:05:42] loss: 4.6202e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:06:02,205 INFO: [vase_..][Iter:     550, lr:(6.333e-06,6.333e-05,)] [eta: 0:05:38] loss: 4.9906e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:06:05,735 INFO: [vase_..][Iter:     560, lr:(6.267e-06,6.267e-05,)] [eta: 0:05:35] loss: 4.5547e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:06:09,291 INFO: [vase_..][Iter:     570, lr:(6.200e-06,6.200e-05,)] [eta: 0:05:31] loss: 9.7618e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:06:12,866 INFO: [vase_..][Iter:     580, lr:(6.133e-06,6.133e-05,)] [eta: 0:05:28] loss: 1.5590e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:06:16,446 INFO: [vase_..][Iter:     590, lr:(6.067e-06,6.067e-05,)] [eta: 0:05:24] loss: 2.8527e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:06:19,981 INFO: [vase_..][Iter:     600, lr:(6.000e-06,6.000e-05,)] [eta: 0:05:20] loss: 4.2874e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:06:23,524 INFO: [vase_..][Iter:     610, lr:(5.933e-06,5.933e-05,)] [eta: 0:05:17] loss: 1.9256e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:06:27,061 INFO: [vase_..][Iter:     620, lr:(5.867e-06,5.867e-05,)] [eta: 0:05:13] loss: 2.9865e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:06:30,594 INFO: [vase_..][Iter:     630, lr:(5.800e-06,5.800e-05,)] [eta: 0:05:10] loss: 4.6234e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:06:34,146 INFO: [vase_..][Iter:     640, lr:(5.733e-06,5.733e-05,)] [eta: 0:05:06] loss: 2.7195e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:06:37,691 INFO: [vase_..][Iter:     650, lr:(5.667e-06,5.667e-05,)] [eta: 0:05:02] loss: 9.1254e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:06:41,231 INFO: [vase_..][Iter:     660, lr:(5.600e-06,5.600e-05,)] [eta: 0:04:59] loss: 1.6498e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:06:44,766 INFO: [vase_..][Iter:     670, lr:(5.533e-06,5.533e-05,)] [eta: 0:04:55] loss: 2.4214e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:06:48,301 INFO: [vase_..][Iter:     680, lr:(5.467e-06,5.467e-05,)] [eta: 0:04:52] loss: 7.5365e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:06:51,844 INFO: [vase_..][Iter:     690, lr:(5.400e-06,5.400e-05,)] [eta: 0:04:48] loss: 1.5148e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:06:55,384 INFO: [vase_..][Iter:     700, lr:(5.333e-06,5.333e-05,)] [eta: 0:04:44] loss: 7.9196e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:06:59,073 INFO: [vase_..][Iter:     710, lr:(5.267e-06,5.267e-05,)] [eta: 0:04:41] loss: 5.3361e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:07:02,608 INFO: [vase_..][Iter:     720, lr:(5.200e-06,5.200e-05,)] [eta: 0:04:37] loss: 1.4394e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:07:06,142 INFO: [vase_..][Iter:     730, lr:(5.133e-06,5.133e-05,)] [eta: 0:04:34] loss: 1.9853e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:07:09,687 INFO: [vase_..][Iter:     740, lr:(5.067e-06,5.067e-05,)] [eta: 0:04:30] loss: 1.5090e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:07:13,240 INFO: [vase_..][Iter:     750, lr:(5.000e-06,5.000e-05,)] [eta: 0:04:27] loss: 7.2195e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:07:16,785 INFO: [vase_..][Iter:     760, lr:(4.933e-06,4.933e-05,)] [eta: 0:04:23] loss: 8.8597e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:07:20,330 INFO: [vase_..][Iter:     770, lr:(4.867e-06,4.867e-05,)] [eta: 0:04:19] loss: 2.8262e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:07:23,897 INFO: [vase_..][Iter:     780, lr:(4.800e-06,4.800e-05,)] [eta: 0:04:16] loss: 2.8104e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:07:27,445 INFO: [vase_..][Iter:     790, lr:(4.733e-06,4.733e-05,)] [eta: 0:04:12] loss: 6.1168e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:07:31,009 INFO: [vase_..][Iter:     800, lr:(4.667e-06,4.667e-05,)] [eta: 0:04:09] loss: 1.6059e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:07:34,574 INFO: [vase_..][Iter:     810, lr:(4.600e-06,4.600e-05,)] [eta: 0:04:05] loss: 3.1623e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:07:38,104 INFO: [vase_..][Iter:     820, lr:(4.533e-06,4.533e-05,)] [eta: 0:04:02] loss: 6.0351e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:07:41,647 INFO: [vase_..][Iter:     830, lr:(4.467e-06,4.467e-05,)] [eta: 0:03:58] loss: 7.0856e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:07:45,210 INFO: [vase_..][Iter:     840, lr:(4.400e-06,4.400e-05,)] [eta: 0:03:54] loss: 3.9960e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:07:48,771 INFO: [vase_..][Iter:     850, lr:(4.333e-06,4.333e-05,)] [eta: 0:03:51] loss: 1.2444e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:07:52,311 INFO: [vase_..][Iter:     860, lr:(4.267e-06,4.267e-05,)] [eta: 0:03:47] loss: 5.4738e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:07:55,876 INFO: [vase_..][Iter:     870, lr:(4.200e-06,4.200e-05,)] [eta: 0:03:44] loss: 6.1061e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:07:59,386 INFO: [vase_..][Iter:     880, lr:(4.133e-06,4.133e-05,)] [eta: 0:03:40] loss: 1.7072e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:08:02,847 INFO: [vase_..][Iter:     890, lr:(4.067e-06,4.067e-05,)] [eta: 0:03:36] loss: 7.8229e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:08:06,325 INFO: [vase_..][Iter:     900, lr:(4.000e-06,4.000e-05,)] [eta: 0:03:33] loss: 8.7205e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:08:09,804 INFO: [vase_..][Iter:     910, lr:(3.933e-06,3.933e-05,)] [eta: 0:03:29] loss: 3.9652e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:08:13,269 INFO: [vase_..][Iter:     920, lr:(3.867e-06,3.867e-05,)] [eta: 0:03:26] loss: 7.8458e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:08:16,735 INFO: [vase_..][Iter:     930, lr:(3.800e-06,3.800e-05,)] [eta: 0:03:22] loss: 3.5439e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:08:20,205 INFO: [vase_..][Iter:     940, lr:(3.733e-06,3.733e-05,)] [eta: 0:03:18] loss: 1.0884e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:08:23,676 INFO: [vase_..][Iter:     950, lr:(3.667e-06,3.667e-05,)] [eta: 0:03:15] loss: 1.8565e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:08:27,131 INFO: [vase_..][Iter:     960, lr:(3.600e-06,3.600e-05,)] [eta: 0:03:11] loss: 1.8756e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:08:30,568 INFO: [vase_..][Iter:     970, lr:(3.533e-06,3.533e-05,)] [eta: 0:03:08] loss: 4.8076e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:08:34,007 INFO: [vase_..][Iter:     980, lr:(3.467e-06,3.467e-05,)] [eta: 0:03:04] loss: 1.0527e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:08:37,463 INFO: [vase_..][Iter:     990, lr:(3.400e-06,3.400e-05,)] [eta: 0:03:00] loss: 1.1519e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:08:40,890 INFO: [vase_..][Iter:   1,000, lr:(3.333e-06,3.333e-05,)] [eta: 0:02:57] loss: 2.0138e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:08:44,314 INFO: [vase_..][Iter:   1,010, lr:(3.267e-06,3.267e-05,)] [eta: 0:02:53] loss: 3.6319e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:08:47,740 INFO: [vase_..][Iter:   1,020, lr:(3.200e-06,3.200e-05,)] [eta: 0:02:49] loss: 9.7695e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:08:51,158 INFO: [vase_..][Iter:   1,030, lr:(3.133e-06,3.133e-05,)] [eta: 0:02:46] loss: 3.4459e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:08:54,589 INFO: [vase_..][Iter:   1,040, lr:(3.067e-06,3.067e-05,)] [eta: 0:02:42] loss: 1.0732e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:08:58,034 INFO: [vase_..][Iter:   1,050, lr:(3.000e-06,3.000e-05,)] [eta: 0:02:39] loss: 1.6908e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:09:01,466 INFO: [vase_..][Iter:   1,060, lr:(2.933e-06,2.933e-05,)] [eta: 0:02:35] loss: 3.3786e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:09:04,960 INFO: [vase_..][Iter:   1,070, lr:(2.867e-06,2.867e-05,)] [eta: 0:02:32] loss: 5.0068e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:09:08,464 INFO: [vase_..][Iter:   1,080, lr:(2.800e-06,2.800e-05,)] [eta: 0:02:28] loss: 1.2990e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:09:11,838 INFO: [vase_..][Iter:   1,090, lr:(2.733e-06,2.733e-05,)] [eta: 0:02:24] loss: 1.6020e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:09:15,209 INFO: [vase_..][Iter:   1,100, lr:(2.667e-06,2.667e-05,)] [eta: 0:02:21] loss: 3.1330e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:09:18,592 INFO: [vase_..][Iter:   1,110, lr:(2.600e-06,2.600e-05,)] [eta: 0:02:17] loss: 7.8803e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:09:21,942 INFO: [vase_..][Iter:   1,120, lr:(2.533e-06,2.533e-05,)] [eta: 0:02:14] loss: 2.5404e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:09:25,303 INFO: [vase_..][Iter:   1,130, lr:(2.467e-06,2.467e-05,)] [eta: 0:02:10] loss: 2.3370e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:09:28,652 INFO: [vase_..][Iter:   1,140, lr:(2.400e-06,2.400e-05,)] [eta: 0:02:06] loss: 6.1583e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:09:32,002 INFO: [vase_..][Iter:   1,150, lr:(2.333e-06,2.333e-05,)] [eta: 0:02:03] loss: 4.4897e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:09:35,360 INFO: [vase_..][Iter:   1,160, lr:(2.267e-06,2.267e-05,)] [eta: 0:01:59] loss: 1.1499e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:09:38,700 INFO: [vase_..][Iter:   1,170, lr:(2.200e-06,2.200e-05,)] [eta: 0:01:56] loss: 8.2477e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:09:42,078 INFO: [vase_..][Iter:   1,180, lr:(2.133e-06,2.133e-05,)] [eta: 0:01:52] loss: 2.2541e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:09:45,488 INFO: [vase_..][Iter:   1,190, lr:(2.067e-06,2.067e-05,)] [eta: 0:01:48] loss: 4.6902e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:09:48,899 INFO: [vase_..][Iter:   1,200, lr:(2.000e-06,2.000e-05,)] [eta: 0:01:45] loss: 2.0007e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:09:52,237 INFO: [vase_..][Iter:   1,210, lr:(1.933e-06,1.933e-05,)] [eta: 0:01:41] loss: 9.8918e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:09:55,577 INFO: [vase_..][Iter:   1,220, lr:(1.867e-06,1.867e-05,)] [eta: 0:01:38] loss: 9.7707e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:09:58,932 INFO: [vase_..][Iter:   1,230, lr:(1.800e-06,1.800e-05,)] [eta: 0:01:34] loss: 1.6048e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:10:02,282 INFO: [vase_..][Iter:   1,240, lr:(1.733e-06,1.733e-05,)] [eta: 0:01:31] loss: 2.9266e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:10:05,689 INFO: [vase_..][Iter:   1,250, lr:(1.667e-06,1.667e-05,)] [eta: 0:01:27] loss: 1.4299e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:10:09,010 INFO: [vase_..][Iter:   1,260, lr:(1.600e-06,1.600e-05,)] [eta: 0:01:24] loss: 1.4573e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:10:12,343 INFO: [vase_..][Iter:   1,270, lr:(1.533e-06,1.533e-05,)] [eta: 0:01:20] loss: 9.3962e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:10:15,666 INFO: [vase_..][Iter:   1,280, lr:(1.467e-06,1.467e-05,)] [eta: 0:01:16] loss: 1.5601e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:10:19,006 INFO: [vase_..][Iter:   1,290, lr:(1.400e-06,1.400e-05,)] [eta: 0:01:13] loss: 4.2128e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:10:22,345 INFO: [vase_..][Iter:   1,300, lr:(1.333e-06,1.333e-05,)] [eta: 0:01:09] loss: 1.0866e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:10:25,696 INFO: [vase_..][Iter:   1,310, lr:(1.267e-06,1.267e-05,)] [eta: 0:01:06] loss: 6.1603e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:10:29,064 INFO: [vase_..][Iter:   1,320, lr:(1.200e-06,1.200e-05,)] [eta: 0:01:02] loss: 1.4867e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:10:32,400 INFO: [vase_..][Iter:   1,330, lr:(1.133e-06,1.133e-05,)] [eta: 0:00:59] loss: 1.4526e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:10:35,754 INFO: [vase_..][Iter:   1,340, lr:(1.067e-06,1.067e-05,)] [eta: 0:00:55] loss: 1.0983e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:10:39,101 INFO: [vase_..][Iter:   1,350, lr:(1.000e-06,1.000e-05,)] [eta: 0:00:52] loss: 4.1926e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:10:42,418 INFO: [vase_..][Iter:   1,360, lr:(9.333e-07,9.333e-06,)] [eta: 0:00:48] loss: 4.6139e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:10:45,762 INFO: [vase_..][Iter:   1,370, lr:(8.667e-07,8.667e-06,)] [eta: 0:00:45] loss: 6.9199e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:10:49,097 INFO: [vase_..][Iter:   1,380, lr:(8.000e-07,8.000e-06,)] [eta: 0:00:41] loss: 4.7231e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:10:52,447 INFO: [vase_..][Iter:   1,390, lr:(7.333e-07,7.333e-06,)] [eta: 0:00:38] loss: 7.6050e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:10:55,828 INFO: [vase_..][Iter:   1,400, lr:(6.667e-07,6.667e-06,)] [eta: 0:00:34] loss: 2.9265e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:10:59,183 INFO: [vase_..][Iter:   1,410, lr:(6.000e-07,6.000e-06,)] [eta: 0:00:31] loss: 1.8519e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:11:02,508 INFO: [vase_..][Iter:   1,420, lr:(5.333e-07,5.333e-06,)] [eta: 0:00:27] loss: 7.7007e-03 Norm_mean: 3.7729e-01 
2024-10-21 22:11:05,842 INFO: [vase_..][Iter:   1,430, lr:(4.667e-07,4.667e-06,)] [eta: 0:00:24] loss: 9.1165e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:11:09,184 INFO: [vase_..][Iter:   1,440, lr:(4.000e-07,4.000e-06,)] [eta: 0:00:20] loss: 4.1981e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:11:12,512 INFO: [vase_..][Iter:   1,450, lr:(3.333e-07,3.333e-06,)] [eta: 0:00:17] loss: 6.4105e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:11:15,827 INFO: [vase_..][Iter:   1,460, lr:(2.667e-07,2.667e-06,)] [eta: 0:00:13] loss: 5.1163e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:11:19,152 INFO: [vase_..][Iter:   1,470, lr:(2.000e-07,2.000e-06,)] [eta: 0:00:10] loss: 3.8272e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:11:22,495 INFO: [vase_..][Iter:   1,480, lr:(1.333e-07,1.333e-06,)] [eta: 0:00:06] loss: 4.7930e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:11:25,839 INFO: [vase_..][Iter:   1,490, lr:(6.667e-08,6.667e-07,)] [eta: 0:00:03] loss: 6.0923e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:11:29,184 INFO: [vase_..][Iter:   1,500, lr:(0.000e+00,0.000e+00,)] [eta: 0:00:00] loss: 1.0950e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:11:29,208 INFO: Save state to /media/hdd2/zfzhao/mix_cleanup2/mix_lora/Mix-of-Show/experiments/vase_r3/models/edlora_model-latest.pth
2024-10-21 22:11:29,208 INFO: Start validation /media/hdd2/zfzhao/mix_cleanup2/mix_lora/Mix-of-Show/experiments/vase_r3/models/edlora_model-latest.pth:
