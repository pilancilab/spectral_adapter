2024-10-21 22:28:52,039 INFO: Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: fp16

2024-10-21 22:28:52,039 INFO: 
  name: vase_r16
  manual_seed: 0
  mixed_precision: fp16
  gradient_accumulation_steps: 1
  datasets:[
    train:[
      name: LoraDataset
      concept_list: datasets/data_cfgs/MixofShow/single-concept/objects/real/vase.json
      use_caption: True
      instance_transform: [{'type': 'Resize', 'size': 512}, {'type': 'RandomCrop', 'size': 512}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': [0.5], 'std': [0.5]}, {'type': 'ShuffleCaption', 'keep_token_num': 1}, {'type': 'EnhanceText', 'enhance_type': 'object'}]
      replace_mapping:[
        <TOK>: <vase1> <vase2>
      ]
      batch_size_per_gpu: 2
      dataset_enlarge_ratio: 500
    ]
    val_vis:[
      name: PromptDataset
      prompts: datasets/validation_prompts/single-concept/objects/test_vase.txt
      num_samples_per_prompt: 8
      latent_size: [4, 64, 64]
      replace_mapping:[
        <TOK>: <vase1> <vase2>
      ]
      batch_size_per_gpu: 4
    ]
  ]
  models:[
    pretrained_path: experiments/pretrained_models/chilloutmix
    enable_edlora: True
    finetune_cfg:[
      text_embedding:[
        enable_tuning: False
        lr: 0.001
      ]
      text_encoder:[
        enable_tuning: True
        lora_cfg:[
          rank: 16
          alpha: 1.0
          where: CLIPAttention
        ]
        lr: 0.0005
      ]
      unet:[
        enable_tuning: True
        lora_cfg:[
          rank: 16
          alpha: 1.0
          where: Attention
        ]
        lr: 0.0001
      ]
    ]
    new_concept_token: <vase1>+<vase2>
    initializer_token: <rand-0.013>+vase
    noise_offset: 0.01
    attn_reg_weight: 0.01
    reg_full_identity: False
    use_mask_loss: True
    gradient_checkpoint: False
    enable_xformers: True
  ]
  path:[
    pretrain_network: None
    experiments_root: /media/hdd2/zfzhao/mix_cleanup2/mix_lidb/Mix-of-Show/experiments/vase_r16
    models: /media/hdd2/zfzhao/mix_cleanup2/mix_lidb/Mix-of-Show/experiments/vase_r16/models
    log: /media/hdd2/zfzhao/mix_cleanup2/mix_lidb/Mix-of-Show/experiments/vase_r16
    visualization: /media/hdd2/zfzhao/mix_cleanup2/mix_lidb/Mix-of-Show/experiments/vase_r16/visualization
  ]
  train:[
    optim_g:[
      type: AdamW
      lr: 0.0
      weight_decay: 0.01
      betas: [0.9, 0.999]
    ]
    unet_kv_drop_rate: 0
    scheduler: linear
    emb_norm_threshold: 0.55
  ]
  val:[
    val_during_save: True
    compose_visualize: True
    alpha_list: [0, 0.7, 1.0]
    sample:[
      num_inference_steps: 50
      guidance_scale: 7.5
    ]
  ]
  logger:[
    print_freq: 10
    save_checkpoint_freq: 10000.0
  ]
  is_train: True

2024-10-21 22:28:55,128 INFO: <vase1> (49408-49423) is random initialized by: <rand-0.013>
2024-10-21 22:28:55,442 INFO: <vase2> (49424-49439) is random initialized by existing token (vase): 20431
2024-10-21 22:28:58,522 INFO: optimizing text_encoder (48 LoRAs), using lr: 0.0005
2024-10-21 22:29:11,312 INFO: optimizing unet (128 LoRAs), using lr: 0.0001
2024-10-21 22:29:12,736 INFO: ***** Running training *****
2024-10-21 22:29:12,737 INFO:   Num examples = 3000
2024-10-21 22:29:12,737 INFO:   Instantaneous batch size per device = 2
2024-10-21 22:29:12,737 INFO:   Total train batch size (w. parallel, distributed & accumulation) = 2
2024-10-21 22:29:12,737 INFO:   Total optimization steps = 1500.0
2024-10-21 22:29:17,088 INFO: [vase_..][Iter:      10, lr:(4.967e-04,9.933e-05,)] [eta: 0:09:48] loss: 3.8945e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:29:20,898 INFO: [vase_..][Iter:      20, lr:(4.933e-04,9.867e-05,)] [eta: 0:09:34] loss: 1.6447e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:29:24,685 INFO: [vase_..][Iter:      30, lr:(4.900e-04,9.800e-05,)] [eta: 0:09:26] loss: 1.5788e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:29:28,465 INFO: [vase_..][Iter:      40, lr:(4.867e-04,9.733e-05,)] [eta: 0:09:19] loss: 5.4953e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:29:32,211 INFO: [vase_..][Iter:      50, lr:(4.833e-04,9.667e-05,)] [eta: 0:09:13] loss: 3.4578e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:29:35,988 INFO: [vase_..][Iter:      60, lr:(4.800e-04,9.600e-05,)] [eta: 0:09:08] loss: 3.0664e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:29:39,755 INFO: [vase_..][Iter:      70, lr:(4.767e-04,9.533e-05,)] [eta: 0:09:03] loss: 3.4765e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:29:43,568 INFO: [vase_..][Iter:      80, lr:(4.733e-04,9.467e-05,)] [eta: 0:09:00] loss: 1.3829e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:29:47,346 INFO: [vase_..][Iter:      90, lr:(4.700e-04,9.400e-05,)] [eta: 0:08:55] loss: 1.2815e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:29:51,160 INFO: [vase_..][Iter:     100, lr:(4.667e-04,9.333e-05,)] [eta: 0:08:52] loss: 1.0994e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:29:55,006 INFO: [vase_..][Iter:     110, lr:(4.633e-04,9.267e-05,)] [eta: 0:08:48] loss: 2.9959e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:29:58,841 INFO: [vase_..][Iter:     120, lr:(4.600e-04,9.200e-05,)] [eta: 0:08:45] loss: 5.7491e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:30:02,682 INFO: [vase_..][Iter:     130, lr:(4.567e-04,9.133e-05,)] [eta: 0:08:41] loss: 2.4078e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:30:06,514 INFO: [vase_..][Iter:     140, lr:(4.533e-04,9.067e-05,)] [eta: 0:08:38] loss: 1.3376e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:30:10,333 INFO: [vase_..][Iter:     150, lr:(4.500e-04,9.000e-05,)] [eta: 0:08:34] loss: 6.5535e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:30:14,147 INFO: [vase_..][Iter:     160, lr:(4.467e-04,8.933e-05,)] [eta: 0:08:30] loss: 7.3878e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:30:17,905 INFO: [vase_..][Iter:     170, lr:(4.433e-04,8.867e-05,)] [eta: 0:08:26] loss: 6.1304e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:30:21,654 INFO: [vase_..][Iter:     180, lr:(4.400e-04,8.800e-05,)] [eta: 0:08:22] loss: 3.8381e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:30:25,368 INFO: [vase_..][Iter:     190, lr:(4.367e-04,8.733e-05,)] [eta: 0:08:17] loss: 9.2158e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:30:29,202 INFO: [vase_..][Iter:     200, lr:(4.333e-04,8.667e-05,)] [eta: 0:08:14] loss: 4.7680e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:30:33,028 INFO: [vase_..][Iter:     210, lr:(4.300e-04,8.600e-05,)] [eta: 0:08:10] loss: 3.7648e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:30:36,926 INFO: [vase_..][Iter:     220, lr:(4.267e-04,8.533e-05,)] [eta: 0:08:07] loss: 7.8858e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:30:40,783 INFO: [vase_..][Iter:     230, lr:(4.233e-04,8.467e-05,)] [eta: 0:08:03] loss: 1.8536e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:30:44,706 INFO: [vase_..][Iter:     240, lr:(4.200e-04,8.400e-05,)] [eta: 0:08:00] loss: 7.9186e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:30:48,556 INFO: [vase_..][Iter:     250, lr:(4.167e-04,8.333e-05,)] [eta: 0:07:56] loss: 7.7914e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:30:52,327 INFO: [vase_..][Iter:     260, lr:(4.133e-04,8.267e-05,)] [eta: 0:07:52] loss: 2.3744e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:30:56,193 INFO: [vase_..][Iter:     270, lr:(4.100e-04,8.200e-05,)] [eta: 0:07:49] loss: 4.9500e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:31:00,050 INFO: [vase_..][Iter:     280, lr:(4.067e-04,8.133e-05,)] [eta: 0:07:45] loss: 2.3229e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:31:03,797 INFO: [vase_..][Iter:     290, lr:(4.033e-04,8.067e-05,)] [eta: 0:07:41] loss: 2.7627e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:31:07,602 INFO: [vase_..][Iter:     300, lr:(4.000e-04,8.000e-05,)] [eta: 0:07:37] loss: 2.4579e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:31:11,499 INFO: [vase_..][Iter:     310, lr:(3.967e-04,7.933e-05,)] [eta: 0:07:34] loss: 5.1975e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:31:15,378 INFO: [vase_..][Iter:     320, lr:(3.933e-04,7.867e-05,)] [eta: 0:07:30] loss: 3.1437e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:31:19,210 INFO: [vase_..][Iter:     330, lr:(3.900e-04,7.800e-05,)] [eta: 0:07:26] loss: 8.0121e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:31:23,142 INFO: [vase_..][Iter:     340, lr:(3.867e-04,7.733e-05,)] [eta: 0:07:23] loss: 4.7811e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:31:26,967 INFO: [vase_..][Iter:     350, lr:(3.833e-04,7.667e-05,)] [eta: 0:07:19] loss: 2.8913e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:31:30,868 INFO: [vase_..][Iter:     360, lr:(3.800e-04,7.600e-05,)] [eta: 0:07:15] loss: 2.7581e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:31:34,762 INFO: [vase_..][Iter:     370, lr:(3.767e-04,7.533e-05,)] [eta: 0:07:12] loss: 1.6951e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:31:38,847 INFO: [vase_..][Iter:     380, lr:(3.733e-04,7.467e-05,)] [eta: 0:07:09] loss: 1.0828e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:31:42,878 INFO: [vase_..][Iter:     390, lr:(3.700e-04,7.400e-05,)] [eta: 0:07:05] loss: 5.9570e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:31:46,921 INFO: [vase_..][Iter:     400, lr:(3.667e-04,7.333e-05,)] [eta: 0:07:02] loss: 5.9697e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:31:51,036 INFO: [vase_..][Iter:     410, lr:(3.633e-04,7.267e-05,)] [eta: 0:06:59] loss: 4.6563e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:31:55,056 INFO: [vase_..][Iter:     420, lr:(3.600e-04,7.200e-05,)] [eta: 0:06:56] loss: 1.7623e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:31:58,900 INFO: [vase_..][Iter:     430, lr:(3.567e-04,7.133e-05,)] [eta: 0:06:52] loss: 3.0644e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:32:03,034 INFO: [vase_..][Iter:     440, lr:(3.533e-04,7.067e-05,)] [eta: 0:06:48] loss: 1.0771e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:32:07,066 INFO: [vase_..][Iter:     450, lr:(3.500e-04,7.000e-05,)] [eta: 0:06:45] loss: 1.1566e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:32:11,068 INFO: [vase_..][Iter:     460, lr:(3.467e-04,6.933e-05,)] [eta: 0:06:41] loss: 1.1923e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:32:14,885 INFO: [vase_..][Iter:     470, lr:(3.433e-04,6.867e-05,)] [eta: 0:06:37] loss: 1.6686e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:32:18,722 INFO: [vase_..][Iter:     480, lr:(3.400e-04,6.800e-05,)] [eta: 0:06:34] loss: 2.7740e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:32:22,703 INFO: [vase_..][Iter:     490, lr:(3.367e-04,6.733e-05,)] [eta: 0:06:30] loss: 2.0130e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:32:26,824 INFO: [vase_..][Iter:     500, lr:(3.333e-04,6.667e-05,)] [eta: 0:06:27] loss: 4.6084e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:32:30,837 INFO: [vase_..][Iter:     510, lr:(3.300e-04,6.600e-05,)] [eta: 0:06:23] loss: 3.5572e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:32:34,913 INFO: [vase_..][Iter:     520, lr:(3.267e-04,6.533e-05,)] [eta: 0:06:19] loss: 1.1218e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:32:38,847 INFO: [vase_..][Iter:     530, lr:(3.233e-04,6.467e-05,)] [eta: 0:06:16] loss: 2.1676e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:32:42,754 INFO: [vase_..][Iter:     540, lr:(3.200e-04,6.400e-05,)] [eta: 0:06:12] loss: 5.2228e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:32:46,840 INFO: [vase_..][Iter:     550, lr:(3.167e-04,6.333e-05,)] [eta: 0:06:08] loss: 5.1820e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:32:50,912 INFO: [vase_..][Iter:     560, lr:(3.133e-04,6.267e-05,)] [eta: 0:06:05] loss: 4.1581e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:32:55,050 INFO: [vase_..][Iter:     570, lr:(3.100e-04,6.200e-05,)] [eta: 0:06:01] loss: 1.0568e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:32:59,156 INFO: [vase_..][Iter:     580, lr:(3.067e-04,6.133e-05,)] [eta: 0:05:58] loss: 1.8904e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:33:03,230 INFO: [vase_..][Iter:     590, lr:(3.033e-04,6.067e-05,)] [eta: 0:05:54] loss: 1.7188e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:33:07,403 INFO: [vase_..][Iter:     600, lr:(3.000e-04,6.000e-05,)] [eta: 0:05:51] loss: 3.6522e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:33:11,545 INFO: [vase_..][Iter:     610, lr:(2.967e-04,5.933e-05,)] [eta: 0:05:47] loss: 2.1595e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:33:15,642 INFO: [vase_..][Iter:     620, lr:(2.933e-04,5.867e-05,)] [eta: 0:05:43] loss: 4.3494e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:33:19,450 INFO: [vase_..][Iter:     630, lr:(2.900e-04,5.800e-05,)] [eta: 0:05:39] loss: 4.9141e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:33:23,004 INFO: [vase_..][Iter:     640, lr:(2.867e-04,5.733e-05,)] [eta: 0:05:35] loss: 1.8225e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:33:26,513 INFO: [vase_..][Iter:     650, lr:(2.833e-04,5.667e-05,)] [eta: 0:05:30] loss: 9.7905e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:33:30,013 INFO: [vase_..][Iter:     660, lr:(2.800e-04,5.600e-05,)] [eta: 0:05:26] loss: 1.1006e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:33:33,490 INFO: [vase_..][Iter:     670, lr:(2.767e-04,5.533e-05,)] [eta: 0:05:22] loss: 1.8995e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:33:36,986 INFO: [vase_..][Iter:     680, lr:(2.733e-04,5.467e-05,)] [eta: 0:05:17] loss: 6.7257e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:33:40,478 INFO: [vase_..][Iter:     690, lr:(2.700e-04,5.400e-05,)] [eta: 0:05:13] loss: 2.1653e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:33:43,986 INFO: [vase_..][Iter:     700, lr:(2.667e-04,5.333e-05,)] [eta: 0:05:09] loss: 9.7570e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:33:47,508 INFO: [vase_..][Iter:     710, lr:(2.633e-04,5.267e-05,)] [eta: 0:05:04] loss: 6.7648e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:33:51,053 INFO: [vase_..][Iter:     720, lr:(2.600e-04,5.200e-05,)] [eta: 0:05:00] loss: 2.3109e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:33:54,604 INFO: [vase_..][Iter:     730, lr:(2.567e-04,5.133e-05,)] [eta: 0:04:56] loss: 2.8338e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:33:58,120 INFO: [vase_..][Iter:     740, lr:(2.533e-04,5.067e-05,)] [eta: 0:04:52] loss: 1.4359e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:34:01,600 INFO: [vase_..][Iter:     750, lr:(2.500e-04,5.000e-05,)] [eta: 0:04:48] loss: 6.0477e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:34:05,104 INFO: [vase_..][Iter:     760, lr:(2.467e-04,4.933e-05,)] [eta: 0:04:43] loss: 6.9627e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:34:08,582 INFO: [vase_..][Iter:     770, lr:(2.433e-04,4.867e-05,)] [eta: 0:04:39] loss: 3.3123e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:34:12,079 INFO: [vase_..][Iter:     780, lr:(2.400e-04,4.800e-05,)] [eta: 0:04:35] loss: 6.3618e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:34:15,594 INFO: [vase_..][Iter:     790, lr:(2.367e-04,4.733e-05,)] [eta: 0:04:31] loss: 7.3245e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:34:19,091 INFO: [vase_..][Iter:     800, lr:(2.333e-04,4.667e-05,)] [eta: 0:04:27] loss: 1.8057e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:34:22,586 INFO: [vase_..][Iter:     810, lr:(2.300e-04,4.600e-05,)] [eta: 0:04:23] loss: 2.1807e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:34:26,212 INFO: [vase_..][Iter:     820, lr:(2.267e-04,4.533e-05,)] [eta: 0:04:19] loss: 4.4512e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:34:29,709 INFO: [vase_..][Iter:     830, lr:(2.233e-04,4.467e-05,)] [eta: 0:04:15] loss: 6.3207e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:34:33,217 INFO: [vase_..][Iter:     840, lr:(2.200e-04,4.400e-05,)] [eta: 0:04:11] loss: 4.4499e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:34:36,718 INFO: [vase_..][Iter:     850, lr:(2.167e-04,4.333e-05,)] [eta: 0:04:07] loss: 1.2021e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:34:40,220 INFO: [vase_..][Iter:     860, lr:(2.133e-04,4.267e-05,)] [eta: 0:04:03] loss: 4.7536e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:34:43,706 INFO: [vase_..][Iter:     870, lr:(2.100e-04,4.200e-05,)] [eta: 0:03:59] loss: 6.6234e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:34:47,177 INFO: [vase_..][Iter:     880, lr:(2.067e-04,4.133e-05,)] [eta: 0:03:54] loss: 1.9631e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:34:50,654 INFO: [vase_..][Iter:     890, lr:(2.033e-04,4.067e-05,)] [eta: 0:03:50] loss: 8.2303e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:34:54,141 INFO: [vase_..][Iter:     900, lr:(2.000e-04,4.000e-05,)] [eta: 0:03:46] loss: 1.0714e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:34:57,673 INFO: [vase_..][Iter:     910, lr:(1.967e-04,3.933e-05,)] [eta: 0:03:43] loss: 4.3698e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:35:01,184 INFO: [vase_..][Iter:     920, lr:(1.933e-04,3.867e-05,)] [eta: 0:03:39] loss: 9.3545e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:35:04,656 INFO: [vase_..][Iter:     930, lr:(1.900e-04,3.800e-05,)] [eta: 0:03:35] loss: 3.7589e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:35:08,146 INFO: [vase_..][Iter:     940, lr:(1.867e-04,3.733e-05,)] [eta: 0:03:31] loss: 9.1640e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:35:11,654 INFO: [vase_..][Iter:     950, lr:(1.833e-04,3.667e-05,)] [eta: 0:03:27] loss: 3.0987e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:35:15,171 INFO: [vase_..][Iter:     960, lr:(1.800e-04,3.600e-05,)] [eta: 0:03:23] loss: 1.6439e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:35:18,703 INFO: [vase_..][Iter:     970, lr:(1.767e-04,3.533e-05,)] [eta: 0:03:19] loss: 4.1915e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:35:22,215 INFO: [vase_..][Iter:     980, lr:(1.733e-04,3.467e-05,)] [eta: 0:03:15] loss: 1.2143e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:35:25,705 INFO: [vase_..][Iter:     990, lr:(1.700e-04,3.400e-05,)] [eta: 0:03:11] loss: 1.1117e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:35:29,223 INFO: [vase_..][Iter:   1,000, lr:(1.667e-04,3.333e-05,)] [eta: 0:03:07] loss: 2.1299e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:35:32,746 INFO: [vase_..][Iter:   1,010, lr:(1.633e-04,3.267e-05,)] [eta: 0:03:03] loss: 4.6021e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:35:36,276 INFO: [vase_..][Iter:   1,020, lr:(1.600e-04,3.200e-05,)] [eta: 0:02:59] loss: 9.8822e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:35:39,803 INFO: [vase_..][Iter:   1,030, lr:(1.567e-04,3.133e-05,)] [eta: 0:02:56] loss: 2.6549e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:35:43,305 INFO: [vase_..][Iter:   1,040, lr:(1.533e-04,3.067e-05,)] [eta: 0:02:52] loss: 7.7196e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:35:46,806 INFO: [vase_..][Iter:   1,050, lr:(1.500e-04,3.000e-05,)] [eta: 0:02:48] loss: 1.8690e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:35:50,316 INFO: [vase_..][Iter:   1,060, lr:(1.467e-04,2.933e-05,)] [eta: 0:02:44] loss: 5.0415e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:35:53,824 INFO: [vase_..][Iter:   1,070, lr:(1.433e-04,2.867e-05,)] [eta: 0:02:40] loss: 5.0610e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:35:57,343 INFO: [vase_..][Iter:   1,080, lr:(1.400e-04,2.800e-05,)] [eta: 0:02:36] loss: 1.6457e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:36:00,868 INFO: [vase_..][Iter:   1,090, lr:(1.367e-04,2.733e-05,)] [eta: 0:02:33] loss: 2.0472e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:36:04,398 INFO: [vase_..][Iter:   1,100, lr:(1.333e-04,2.667e-05,)] [eta: 0:02:29] loss: 6.0547e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:36:07,908 INFO: [vase_..][Iter:   1,110, lr:(1.300e-04,2.600e-05,)] [eta: 0:02:25] loss: 8.0810e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:36:11,426 INFO: [vase_..][Iter:   1,120, lr:(1.267e-04,2.533e-05,)] [eta: 0:02:21] loss: 3.5434e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:36:14,943 INFO: [vase_..][Iter:   1,130, lr:(1.233e-04,2.467e-05,)] [eta: 0:02:17] loss: 3.9006e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:36:18,436 INFO: [vase_..][Iter:   1,140, lr:(1.200e-04,2.400e-05,)] [eta: 0:02:13] loss: 7.3144e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:36:21,953 INFO: [vase_..][Iter:   1,150, lr:(1.167e-04,2.333e-05,)] [eta: 0:02:10] loss: 6.4402e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:36:25,470 INFO: [vase_..][Iter:   1,160, lr:(1.133e-04,2.267e-05,)] [eta: 0:02:06] loss: 9.1561e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:36:28,983 INFO: [vase_..][Iter:   1,170, lr:(1.100e-04,2.200e-05,)] [eta: 0:02:02] loss: 1.6360e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:36:32,497 INFO: [vase_..][Iter:   1,180, lr:(1.067e-04,2.133e-05,)] [eta: 0:01:58] loss: 3.3844e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:36:36,008 INFO: [vase_..][Iter:   1,190, lr:(1.033e-04,2.067e-05,)] [eta: 0:01:55] loss: 3.3308e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:36:39,537 INFO: [vase_..][Iter:   1,200, lr:(1.000e-04,2.000e-05,)] [eta: 0:01:51] loss: 1.4814e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:36:43,049 INFO: [vase_..][Iter:   1,210, lr:(9.667e-05,1.933e-05,)] [eta: 0:01:47] loss: 7.5545e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:36:46,572 INFO: [vase_..][Iter:   1,220, lr:(9.333e-05,1.867e-05,)] [eta: 0:01:43] loss: 2.1242e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:36:50,095 INFO: [vase_..][Iter:   1,230, lr:(9.000e-05,1.800e-05,)] [eta: 0:01:39] loss: 2.2038e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:36:53,612 INFO: [vase_..][Iter:   1,240, lr:(8.667e-05,1.733e-05,)] [eta: 0:01:36] loss: 4.5603e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:36:57,128 INFO: [vase_..][Iter:   1,250, lr:(8.333e-05,1.667e-05,)] [eta: 0:01:32] loss: 1.3110e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:37:00,632 INFO: [vase_..][Iter:   1,260, lr:(8.000e-05,1.600e-05,)] [eta: 0:01:28] loss: 7.1753e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:37:04,169 INFO: [vase_..][Iter:   1,270, lr:(7.667e-05,1.533e-05,)] [eta: 0:01:24] loss: 8.7608e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:37:07,721 INFO: [vase_..][Iter:   1,280, lr:(7.333e-05,1.467e-05,)] [eta: 0:01:21] loss: 1.2644e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:37:11,262 INFO: [vase_..][Iter:   1,290, lr:(7.000e-05,1.400e-05,)] [eta: 0:01:17] loss: 2.9144e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:37:14,772 INFO: [vase_..][Iter:   1,300, lr:(6.667e-05,1.333e-05,)] [eta: 0:01:13] loss: 9.1142e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:37:18,262 INFO: [vase_..][Iter:   1,310, lr:(6.333e-05,1.267e-05,)] [eta: 0:01:09] loss: 7.6232e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:37:21,779 INFO: [vase_..][Iter:   1,320, lr:(6.000e-05,1.200e-05,)] [eta: 0:01:06] loss: 1.3423e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:37:25,272 INFO: [vase_..][Iter:   1,330, lr:(5.667e-05,1.133e-05,)] [eta: 0:01:02] loss: 1.1123e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:37:28,786 INFO: [vase_..][Iter:   1,340, lr:(5.333e-05,1.067e-05,)] [eta: 0:00:58] loss: 1.1807e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:37:32,271 INFO: [vase_..][Iter:   1,350, lr:(5.000e-05,1.000e-05,)] [eta: 0:00:55] loss: 3.8980e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:37:35,779 INFO: [vase_..][Iter:   1,360, lr:(4.667e-05,9.333e-06,)] [eta: 0:00:51] loss: 4.8690e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:37:39,279 INFO: [vase_..][Iter:   1,370, lr:(4.333e-05,8.667e-06,)] [eta: 0:00:47] loss: 5.5571e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:37:42,771 INFO: [vase_..][Iter:   1,380, lr:(4.000e-05,8.000e-06,)] [eta: 0:00:43] loss: 6.8558e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:37:46,287 INFO: [vase_..][Iter:   1,390, lr:(3.667e-05,7.333e-06,)] [eta: 0:00:40] loss: 8.2983e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:37:49,809 INFO: [vase_..][Iter:   1,400, lr:(3.333e-05,6.667e-06,)] [eta: 0:00:36] loss: 4.7281e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:37:53,303 INFO: [vase_..][Iter:   1,410, lr:(3.000e-05,6.000e-06,)] [eta: 0:00:32] loss: 2.6948e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:37:56,819 INFO: [vase_..][Iter:   1,420, lr:(2.667e-05,5.333e-06,)] [eta: 0:00:29] loss: 1.3419e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:38:00,310 INFO: [vase_..][Iter:   1,430, lr:(2.333e-05,4.667e-06,)] [eta: 0:00:25] loss: 1.1365e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:38:03,796 INFO: [vase_..][Iter:   1,440, lr:(2.000e-05,4.000e-06,)] [eta: 0:00:21] loss: 4.1730e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:38:07,283 INFO: [vase_..][Iter:   1,450, lr:(1.667e-05,3.333e-06,)] [eta: 0:00:18] loss: 4.5326e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:38:10,782 INFO: [vase_..][Iter:   1,460, lr:(1.333e-05,2.667e-06,)] [eta: 0:00:14] loss: 7.0921e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:38:14,291 INFO: [vase_..][Iter:   1,470, lr:(1.000e-05,2.000e-06,)] [eta: 0:00:10] loss: 8.9522e-02 Norm_mean: 3.7729e-01 
2024-10-21 22:38:17,830 INFO: [vase_..][Iter:   1,480, lr:(6.667e-06,1.333e-06,)] [eta: 0:00:06] loss: 6.2202e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:38:21,336 INFO: [vase_..][Iter:   1,490, lr:(3.333e-06,6.667e-07,)] [eta: 0:00:03] loss: 6.3188e-01 Norm_mean: 3.7729e-01 
2024-10-21 22:38:24,837 INFO: [vase_..][Iter:   1,500, lr:(0.000e+00,0.000e+00,)] [eta: 0:00:00] loss: 1.0149e+00 Norm_mean: 3.7729e-01 
2024-10-21 22:38:25,003 INFO: Save state to /media/hdd2/zfzhao/mix_cleanup2/mix_lidb/Mix-of-Show/experiments/vase_r16/models/edlora_model-latest.pth
2024-10-21 22:38:25,004 INFO: Start validation /media/hdd2/zfzhao/mix_cleanup2/mix_lidb/Mix-of-Show/experiments/vase_r16/models/edlora_model-latest.pth:
